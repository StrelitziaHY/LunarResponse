{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6560233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import simps, cumulative_trapezoid\n",
    "from scipy.constants import G as Const_G # Gravitational constant (SI units)\n",
    "import os\n",
    "import warnings\n",
    "from joblib import Parallel, delayed # For parallelization\n",
    "import sys # For flushing output\n",
    "\n",
    "# Suppress RuntimeWarnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in true_divide')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='divide by zero encountered in true_divide')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in power')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='divide by zero encountered in power')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in multiply')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in subtract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16242ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def _derivative(y, x):\n",
    "    \"\"\"Calculate the derivative using np.gradient.\"\"\"\n",
    "    return np.gradient(y, x, edge_order=2)\n",
    "\n",
    "def _integrate(y, x):\n",
    "    \"\"\"Integrate using Simpson's rule.\"\"\"\n",
    "    return simps(y, x)\n",
    "\n",
    "def _cumulative_integrate(y, x, initial=0):\n",
    "    \"\"\"Cumulative integration using trapezoidal rule.\"\"\"\n",
    "    return cumulative_trapezoid(y, x, initial=initial)\n",
    "\n",
    "def _get_k_ang(l_val):\n",
    "    \"\"\"Calculate angular wavenumber k_l.\"\"\"\n",
    "    return np.sqrt(l_val * (l_val + 1)) if l_val > 0 else 1e-9\n",
    "\n",
    "def _load_frequencies_from_res1(res1_path, sigma_char, target_map, nl_tuples_to_consider):\n",
    "    \"\"\"\n",
    "    Helper function to load frequencies from a res1.txt file.\n",
    "    nl_tuples_to_consider is a list of (n,l) tuples.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to load {sigma_char}-mode frequencies from: {res1_path}\")\n",
    "    nl_set_to_consider = set(nl_tuples_to_consider)\n",
    "    if not nl_set_to_consider:\n",
    "        print(f\"  No {sigma_char}-modes specified for loading frequencies.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(res1_path):\n",
    "        try:\n",
    "            data_freq = np.loadtxt(res1_path, comments='#')\n",
    "            if data_freq.ndim == 1: data_freq = data_freq.reshape(1, -1)\n",
    "            \n",
    "            loaded_count = 0\n",
    "            for row in data_freq:\n",
    "                n_file, l_file = int(row[0]), int(row[1])\n",
    "                if (n_file, l_file) not in nl_set_to_consider:\n",
    "                    continue\n",
    "                \n",
    "                # Assuming format: n l T Q f(mHz)\n",
    "                # Or format: n l T f(mHz)\n",
    "                try:\n",
    "                    freq_mhz = float(row[3]) # Standard format\n",
    "                except IndexError:\n",
    "                    print(f\"  Warning: Row format unexpected for {n_file},{l_file}. Skipping.\")\n",
    "                    continue\n",
    "                    \n",
    "                omega_sq_val = (freq_mhz * 1e-3 * 2 * np.pi)**2\n",
    "                if omega_sq_val > 1e-20:\n",
    "                    target_map[(sigma_char, n_file, l_file)] = omega_sq_val\n",
    "                    loaded_count += 1\n",
    "                else:\n",
    "                    print(f\"  Warning: Skipping zero/negative omega_sq ({omega_sq_val:.2e}) for ({sigma_char},{n_file},{l_file})\")\n",
    "            print(f\"  Successfully loaded {loaded_count} relevant {sigma_char}-mode frequencies.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error parsing {res1_path}: {e}. Frequencies for {sigma_char}-modes might be missing.\")\n",
    "    else:\n",
    "        print(f\"  Warning: Eigenfrequency file '{res1_path}' for {sigma_char}-modes not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d28417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: The Main Simplified S2 Calculator Class\n",
    "\n",
    "class SimplifiedS2Calculator:\n",
    "    \"\"\"\n",
    "    A simplified calculator for spherically symmetric (s=0) perturbations\n",
    "    coupling Spheroidal l=2 modes with other Spheroidal l=2 modes.\n",
    "    \n",
    "    Provides functions to calculate V_mat - omega^2 * T_mat coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 all_s2_n_values, \n",
    "                 model_file, \n",
    "                 eigenfunction_folder_spher,\n",
    "                 omega_k2_map,\n",
    "                 G_const=0.0 # IMPORTANT: Set to 0.0 to match original code's logic\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initializes the calculator by loading the model and all specified\n",
    "        S, l=2 eigenfunctions.\n",
    "\n",
    "        Args:\n",
    "            all_s2_n_values (list): List of n values for l=2 [0, 1, 2, ...].\n",
    "            model_file (str): Path to the background model file.\n",
    "            eigenfunction_folder_spher (str): Path to the folder with S-mode eigenfunctions.\n",
    "            omega_k2_map (dict): Pre-loaded map of {('S', n, 2): omega_k_sq}.\n",
    "            G_const (float): Gravitational constant. Per original code, this is 0.0.\n",
    "                             Set to Const_G (from scipy) for physical calculations.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"--- Initializing SimplifiedS2Calculator ---\")\n",
    "        \n",
    "        # --- Store constants and parameters ---\n",
    "        self.l = 2\n",
    "        self.k_ang = _get_k_ang(self.l)\n",
    "        self.G = G_const # Set G (0.0 based on original code)\n",
    "        if self.G == 0.0:\n",
    "            print(\"Warning: Gravitational constant G is set to 0.0 (matching original code logic).\")\n",
    "            print(\"         This means g_model, p_val, and V_rho kernel will be 0.\")\n",
    "        \n",
    "        # --- B-factors and Angular Factor for S=0, L=2, SS coupling ---\n",
    "        # These are derived from the original code's logic for this specific case\n",
    "        self.B0_PLUS_S0L2 = 1.0 / np.sqrt(5.0)\n",
    "        self.B1_PLUS_S0L2 = 6.0 / np.sqrt(5.0)\n",
    "        self.B2_PLUS_S0L2 = 24.0 / np.sqrt(5.0)\n",
    "        self.ANGULAR_FACTOR_S0L2 = np.sqrt(5.0) # Combined (Ang. Factor * Pert. Factor)\n",
    "\n",
    "        # --- Load Background Model ---\n",
    "        print(f\"Loading background model from: {model_file}\")\n",
    "        try:\n",
    "            self._load_background_model(model_file)\n",
    "            self.R_surface = self.r_model[-1]\n",
    "            print(f\"Model loaded: {len(self.r_model)} radial points, R = {self.R_surface / 1e3:.1f} km\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model file: {e}\")\n",
    "            raise\n",
    "\n",
    "        # --- Validate and Prepare Eigenfunctions ---\n",
    "        self.eigen_data = {}\n",
    "        self.omega_k2_map_instance = {}\n",
    "        \n",
    "        # Filter k_tuples to only those with valid omega\n",
    "        self.k_values_with_data = []\n",
    "        for n_val in sorted(list(set(all_s2_n_values))):\n",
    "            k_tuple = ('S', n_val, self.l)\n",
    "            if k_tuple not in omega_k2_map:\n",
    "                print(f\"  Skipping {k_tuple}: Frequency not found in provided omega_k2_map.\")\n",
    "                continue\n",
    "            if omega_k2_map[k_tuple] <= 1e-20:\n",
    "                 print(f\"  Skipping {k_tuple}: Non-positive omega_k^2 ({omega_k2_map[k_tuple]:.2e}).\")\n",
    "                 continue\n",
    "            \n",
    "            try:\n",
    "                # Check file existence *before* adding to list\n",
    "                self._check_eigenfunction_file_exists(k_tuple, eigenfunction_folder_spher)\n",
    "                self.k_values_with_data.append(k_tuple)\n",
    "                self.omega_k2_map_instance[k_tuple] = omega_k2_map[k_tuple]\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"  Skipping {k_tuple}: Eigenfunction file not found ({e}).\")\n",
    "\n",
    "        self.num_k_modes = len(self.k_values_with_data)\n",
    "        if self.num_k_modes == 0:\n",
    "            print(\"Warning: No valid modes found with both frequency and eigenfunction data.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nFound {self.num_k_modes} valid (S, n, 2) modes to process.\")\n",
    "        \n",
    "        # --- Process Eigenfunctions ---\n",
    "        self._prepare_all_eigenfunctions(eigenfunction_folder_spher)\n",
    "        print(\"--- Initialization Complete ---\")\n",
    "\n",
    "    \n",
    "    def _load_background_model(self, modname):\n",
    "        model = np.loadtxt(modname, skiprows=0)\n",
    "        self.r_model = model[:, 0]\n",
    "        self.rho_model = model[:, 1]\n",
    "        self.vp_model = model[:, 2]\n",
    "        self.vs_model = model[:, 3]\n",
    "        self.mu_model = self.rho_model * self.vs_model**2\n",
    "        self.kappa_model = self.rho_model * (self.vp_model**2 - (4.0/3.0) * self.vs_model**2)\n",
    "        self.kappa_model[self.kappa_model < 0] = 0\n",
    "        self.r_stable = np.maximum(self.r_model, 1e-10)\n",
    "        \n",
    "        # g_model calculation depends on self.G\n",
    "        mass_integrand = self.rho_model * self.r_model**2\n",
    "        mass_r = 4 * np.pi * _cumulative_integrate(mass_integrand, self.r_model)\n",
    "        self.g_model = np.divide(-self.G * mass_r, self.r_stable**2, \n",
    "                                 out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        if len(self.g_model)>0: self.g_model[0] = 0.0\n",
    "\n",
    "    def _get_eigen_fname_path(self, k_tuple, eigenfunction_folder_spher):\n",
    "        sigma_char, n_val, l_val = k_tuple\n",
    "        n_str_formatted = f\"{n_val:07d}\"\n",
    "        l_str_formatted = f\"{l_val:07d}\"\n",
    "        prefix = \"S.\"\n",
    "        filename_path = os.path.join(eigenfunction_folder_spher, \n",
    "                                     f\"{prefix}{n_str_formatted}.{l_str_formatted}.ASC\")\n",
    "        if not os.path.exists(filename_path):\n",
    "             raise FileNotFoundError(filename_path)\n",
    "        return filename_path\n",
    "\n",
    "    def _check_eigenfunction_file_exists(self, k_tuple, eigenfunction_folder_spher):\n",
    "        self._get_eigen_fname_path(k_tuple, eigenfunction_folder_spher)\n",
    "\n",
    "    def _load_single_eigenfunction(self, k_tuple, eigenfunction_folder_spher):\n",
    "        sigma_char, n_val, l_val = k_tuple\n",
    "        filename = self._get_eigen_fname_path(k_tuple, eigenfunction_folder_spher)\n",
    "        \n",
    "        df = pd.read_csv(filename, skiprows=1, header=None, delim_whitespace=True)\n",
    "        \n",
    "        U_M_raw = np.array(df[1], dtype=float)[::-1]\n",
    "        V_M_raw = np.array(df[3], dtype=float)[::-1]\n",
    "\n",
    "        if len(U_M_raw) != len(self.r_model) or len(V_M_raw) != len(self.r_model):\n",
    "            raise ValueError(f\"Length mismatch for S-mode {k_tuple}. File: {filename}.\")\n",
    "\n",
    "        # Note: l=0 logic removed as we are fixed to l=2\n",
    "        norm_integrand = self.rho_model * \\\n",
    "                         (U_M_raw**2 + self.k_ang**2 * V_M_raw**2) * \\\n",
    "                         self.r_model**2\n",
    "        \n",
    "        norm_factor_val_sq = _integrate(norm_integrand, self.r_model)\n",
    "\n",
    "        if norm_factor_val_sq < 1e-20:\n",
    "            print(f\"Warning: S-mode Normalization factor squared for {k_tuple} is small ({norm_factor_val_sq}).\")\n",
    "            norm_factor_sqrt = 1e10\n",
    "        else:\n",
    "            norm_factor_sqrt = np.sqrt(norm_factor_val_sq)\n",
    "        \n",
    "        U_latex = U_M_raw / norm_factor_sqrt\n",
    "        V_latex = (self.k_ang * V_M_raw) / norm_factor_sqrt\n",
    "        \n",
    "        return {'U_latex': U_latex, 'V_latex': V_latex}\n",
    "\n",
    "    def _process_single_eigenfunction_job(self, k_tuple_job, eigenfunction_folder_spher_job):\n",
    "        \"\"\"Processes one eigenfunction, calculating all derivatives and fields.\"\"\"\n",
    "        sigma_char, n_val, l_val = k_tuple_job\n",
    "        \n",
    "        raw_efuncs_latex = self._load_single_eigenfunction(k_tuple_job, \n",
    "                                                           eigenfunction_folder_spher_job)\n",
    "        data = {'sigma': sigma_char, 'n': n_val, 'l': l_val}\n",
    "        \n",
    "        data['u'] = raw_efuncs_latex['U_latex']\n",
    "        data['v_div_k'] = np.divide(raw_efuncs_latex['V_latex'], self.k_ang, \n",
    "                                    out=np.zeros_like(raw_efuncs_latex['V_latex']), \n",
    "                                    where=self.k_ang!=0)\n",
    "        \n",
    "        data['dot_u'] = _derivative(data['u'], self.r_model)\n",
    "        data['dot_v_div_k'] = _derivative(data['v_div_k'], self.r_model)\n",
    "        \n",
    "        data['f_val'] = np.divide(2*data['u'] - self.k_ang**2 * data['v_div_k'], self.r_stable, \n",
    "                                  out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        \n",
    "        term_v_div_k_r = np.divide(data['v_div_k'], self.r_stable, \n",
    "                                   out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        term_u_r = np.divide(data['u'], self.r_stable, \n",
    "                             out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        data['x_val'] = data['dot_v_div_k'] - term_v_div_k_r + term_u_r\n",
    "        \n",
    "        # --- P_val calculation (depends on self.G) ---\n",
    "        V_for_P_calc = raw_efuncs_latex['V_latex']\n",
    "        \n",
    "        integrand1_p = self.rho_model * (self.l * data['u'] + V_for_P_calc) * self.r_stable**(self.l + 1)\n",
    "        integrand2_p = self.rho_model * (-(self.l + 1) * data['u'] + V_for_P_calc) * \\\n",
    "                       np.power(self.r_stable, -self.l, \n",
    "                                out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        \n",
    "        int1_p = _cumulative_integrate(integrand1_p, self.r_model)\n",
    "        int2_total_p = _integrate(integrand2_p, self.r_model)\n",
    "        int2_cumulative_p = _cumulative_integrate(integrand2_p, self.r_model)\n",
    "        int2_rev_p = int2_total_p - int2_cumulative_p\n",
    "        \n",
    "        P_term1 = np.divide(int1_p, np.power(self.r_stable, self.l + 1, \n",
    "                                            out=np.ones_like(self.r_model), where=self.r_stable!=0),\n",
    "                            out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        P_term2 = int2_rev_p * np.power(self.r_stable, self.l, \n",
    "                                        out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        \n",
    "        data['p_val'] = -4 * np.pi * self.G / (2*self.l + 1) * (P_term1 + P_term2) # Use self.G\n",
    "        if len(data['p_val']) > 0: data['p_val'][0] = 0.0\n",
    "        data['dot_p'] = _derivative(data['p_val'], self.r_model)\n",
    "\n",
    "        return k_tuple_job, data\n",
    "\n",
    "    def _prepare_all_eigenfunctions(self, eigenfunction_folder_spher):\n",
    "        print(\"Preparing all eigenfunction derivatives (S,l=2) (parallelized)...\")\n",
    "        \n",
    "        tasks = [delayed(self._process_single_eigenfunction_job)(k_tuple, eigenfunction_folder_spher)\n",
    "                 for k_tuple in self.k_values_with_data]\n",
    "        \n",
    "        # Use n_jobs=-2 (all cores but one) or a fixed number\n",
    "        results = Parallel(n_jobs=-2, backend='loky', verbose=5)(tasks) \n",
    "\n",
    "        for k_tuple_res, data_res in results:\n",
    "            self.eigen_data[k_tuple_res] = data_res\n",
    "        \n",
    "        print(f\"\\nAll {len(self.k_values_with_data)} (S,l=2) eigenfunctions processed.\")\n",
    "\n",
    "    def _get_kernels_s0_l2_ss(self, data_k1, data_k2):\n",
    "        \"\"\"\n",
    "        Calculates the SS kernels for s_pert=0, l=2, simplified logic.\n",
    "        \"\"\"\n",
    "        kernels = {}\n",
    "        \n",
    "        # Get pre-calculated B-factors\n",
    "        B0p = self.B0_PLUS_S0L2\n",
    "        B1p = self.B1_PLUS_S0L2\n",
    "        B2p = self.B2_PLUS_S0L2\n",
    "        \n",
    "        # Get model data\n",
    "        r_stable = self.r_stable\n",
    "        rho_model = self.rho_model\n",
    "        g_model = self.g_model\n",
    "        kappa_model = self.kappa_model\n",
    "        mu_model = self.mu_model\n",
    "        \n",
    "        # Get eigenfunction data\n",
    "        u1,v1dk,du1,f1,x1,p1,dp1 = (data_k1['u'], data_k1['v_div_k'], data_k1['dot_u'],\n",
    "                                   data_k1['f_val'], data_k1['x_val'], data_k1['p_val'],\n",
    "                                   data_k1['dot_p'])\n",
    "        u2,v2dk,du2,f2,x2,p2,dp2 = (data_k2['u'], data_k2['v_div_k'], data_k2['dot_u'],\n",
    "                                   data_k2['f_val'], data_k2['x_val'], data_k2['p_val'],\n",
    "                                   data_k2['dot_p'])\n",
    "\n",
    "        # --- T_rho Kernel ---\n",
    "        kernels['T_rho_SS'] = u1*u2*B0p + v1dk*v2dk*B1p\n",
    "        \n",
    "        # --- V_kappa Kernel ---\n",
    "        kernels['V_kappa_SS'] = (du1+f1)*(du2+f2)*B0p\n",
    "        \n",
    "        # --- V_mu Kernel ---\n",
    "        V_mu_SS_term1 = (1./3.)*(2*du1-f1)*(2*du2-f2)*B0p\n",
    "        V_mu_SS_term2 = x1*x2*B1p\n",
    "        V_mu_SS_term3 = np.divide(v1dk*v2dk, r_stable**2, \n",
    "                                  out=np.zeros_like(rho_model), where=(r_stable!=0))*B2p\n",
    "        kernels['V_mu_SS'] = V_mu_SS_term1 + V_mu_SS_term2 + V_mu_SS_term3\n",
    "\n",
    "        # --- V_rho Kernel (depends on G) ---\n",
    "        V_rho_SS_term1 = (u1*dp2 + dp1*u2 - 0.5*g_model * \\\n",
    "                         (np.divide(4*u1*u2,r_stable,out=np.zeros_like(rho_model),where=r_stable!=0) + f1*u2 + u1*f2) + \\\n",
    "                         8*np.pi*self.G*rho_model*u1*u2)*B0p\n",
    "        V_rho_SS_term2 = np.divide((p1*v2dk + v1dk*p2) + 0.5*g_model*(u1*v2dk + v1dk*u2), \\\n",
    "                                 r_stable, out=np.zeros_like(rho_model), where=r_stable!=0)*B1p\n",
    "        kernels['V_rho_SS'] = V_rho_SS_term1 + V_rho_SS_term2\n",
    "        \n",
    "        # --- V_d Kernel (simplified for s=0) ---\n",
    "        Vd_SS_term_bg = -kappa_model*kernels['V_kappa_SS'] \\\n",
    "                        -mu_model*kernels['V_mu_SS'] \\\n",
    "                        -rho_model*kernels['V_rho_SS']\n",
    "        \n",
    "        Vd_SS_kappa_deriv = kappa_model*( \\\n",
    "                                      (2*du1*du2 + du1*f2 + f1*du2)*B0p \\\n",
    "                                      # B_l2_l1_s_1_plus term is 0 for s=0, l=2\n",
    "                                      # B_l1_l2_s_1_plus term is 0 for s=0, l=2\n",
    "                                      )\n",
    "        Vd_SS_mu_deriv = mu_model*( \\\n",
    "                                    (2./3.)*(4*du1*du2 - du1*f2 - f1*du2)*B0p \\\n",
    "                                    + (data_k1['dot_v_div_k']*x2 + x1*data_k2['dot_v_div_k'])*B1p \\\n",
    "                                    # B_l2_l1_s_1_plus term is 0 for s=0, l=2\n",
    "                                    # B_l1_l2_s_1_plus term is 0 for s=0, l=2\n",
    "                                    )\n",
    "        kernels['V_d_SS'] = Vd_SS_term_bg + Vd_SS_kappa_deriv + Vd_SS_mu_deriv\n",
    "        \n",
    "        # --- T_d Kernel ---\n",
    "        kernels['T_d_SS'] = -rho_model * kernels['T_rho_SS']\n",
    "        \n",
    "        return kernels\n",
    "\n",
    "    def _get_jump_value(self, r_interface, kernel_array, \n",
    "                        surface_proximity_threshold=500.0, jump_half_width=50.0):\n",
    "        \"\"\"Calculates the jump [f] = f(r_i+) - f(r_i-) for a kernel array.\"\"\"\n",
    "        \n",
    "        # Check if it's a surface perturbation\n",
    "        if abs(r_interface - self.R_surface) < surface_proximity_threshold:\n",
    "            # Surface jump: [f] = f(R+) - f(R-) = 0.0 - f(R-)\n",
    "            jump_val = 0.0 - kernel_array[-1]\n",
    "        else:\n",
    "            # Internal interface jump\n",
    "            jump_val = 0.0\n",
    "            idx_below_arr = np.where(self.r_model < (r_interface - jump_half_width))[0]\n",
    "            idx_above_arr = np.where(self.r_model >= (r_interface + jump_half_width))[0]\n",
    "            \n",
    "            if len(idx_below_arr) > 0 and len(idx_above_arr) > 0:\n",
    "                idx_b, idx_a = idx_below_arr[-1], idx_above_arr[0]\n",
    "                if idx_b < idx_a and idx_a < len(self.r_model):\n",
    "                    # [f] = f(r_i+) - f(r_i-)\n",
    "                    jump_val = kernel_array[idx_a] - kernel_array[idx_b]\n",
    "            else:\n",
    "                print(f\"Warning: Could not find points above/below interface r={r_interface}.\"\n",
    "                      f\" Jump value will be 0.\")\n",
    "        \n",
    "        return jump_val\n",
    "\n",
    "    # --- Public Functions (Requirement 2 & 3) ---\n",
    "\n",
    "    def calculate_coupling_term(self, n1, n2, pert_type, pert_profile, omega_n2_sq):\n",
    "        \"\"\"\n",
    "        Calculates V_mat(n1, n2) - omega_n2^2 * T_mat(n1, n2) for a specific \n",
    "        perturbation type and profile.\n",
    "\n",
    "        Args:\n",
    "            n1 (int): Radial quantum number of mode 1 (bra).\n",
    "            n2 (int): Radial quantum number of mode 2 (ket).\n",
    "            pert_type (str): 'delta_rho', 'delta_mu', 'delta_kappa', or 'delta_d'.\n",
    "            pert_profile (tuple or float): \n",
    "                - For 'delta_rho', 'mu', 'kappa': (r_min, r_max) tuple.\n",
    "                - For 'delta_d': r_interface (float).\n",
    "            omega_n2_sq (float): Unperturbed omega^2 for mode n2.\n",
    "\n",
    "        Returns:\n",
    "            float: The value of V_mat - omega_n2^2 * T_mat.\n",
    "        \"\"\"\n",
    "        k1_tuple = ('S', n1, self.l)\n",
    "        k2_tuple = ('S', n2, self.l)\n",
    "\n",
    "        # Check if we have data for these modes\n",
    "        if k1_tuple not in self.eigen_data or k2_tuple not in self.eigen_data:\n",
    "            print(f\"Error: Eigenfunction data not found for {k1_tuple} or {k2_tuple}.\")\n",
    "            print(f\"Available n values: {[k[1] for k in self.k_values_with_data]}\")\n",
    "            return np.nan\n",
    "\n",
    "        data_k1 = self.eigen_data[k1_tuple]\n",
    "        data_k2 = self.eigen_data[k2_tuple]\n",
    "\n",
    "        # Get the s=0, l=2, SS kernels\n",
    "        kernels_s0 = self._get_kernels_s0_l2_ss(data_k1, data_k2)\n",
    "\n",
    "        V_mat = 0.0\n",
    "        T_mat = 0.0\n",
    "        r = self.r_model\n",
    "        \n",
    "        if pert_type in ['delta_rho', 'delta_mu', 'delta_kappa']:\n",
    "            r_min, r_max = pert_profile\n",
    "            # Create perturbation profile P(r) = 1 inside range, 0 outside\n",
    "            P_r = np.zeros_like(r)\n",
    "            mask = (r >= r_min) & (r <= r_max)\n",
    "            P_r[mask] = 1.0\n",
    "\n",
    "            if pert_type == 'delta_rho':\n",
    "                # V_rho_SS kernel is 0 if G=0\n",
    "                kernel_V = kernels_s0['V_rho_SS'] \n",
    "                kernel_T = kernels_s0['T_rho_SS']\n",
    "                integrand_V = P_r * kernel_V * r**2\n",
    "                integrand_T = P_r * kernel_T * r**2\n",
    "                V_mat = self.ANGULAR_FACTOR_S0L2 * _integrate(integrand_V, r)\n",
    "                T_mat = self.ANGULAR_FACTOR_S0L2 * _integrate(integrand_T, r)\n",
    "                \n",
    "            elif pert_type == 'delta_mu':\n",
    "                kernel_V = kernels_s0['V_mu_SS']\n",
    "                kernel_T = 0.0 # No T_mu kernel\n",
    "                integrand_V = P_r * kernel_V * r**2\n",
    "                V_mat = self.ANGULAR_FACTOR_S0L2 * _integrate(integrand_V, r)\n",
    "                T_mat = 0.0\n",
    "\n",
    "            elif pert_type == 'delta_kappa':\n",
    "                kernel_V = kernels_s0['V_kappa_SS']\n",
    "                kernel_T = 0.0 # No T_kappa kernel\n",
    "                integrand_V = P_r * kernel_V * r**2\n",
    "                V_mat = self.ANGULAR_FACTOR_S0L2 * _integrate(integrand_V, r)\n",
    "                T_mat = 0.0\n",
    "        \n",
    "        elif pert_type == 'delta_d':\n",
    "            r_interface = pert_profile\n",
    "            d_val = 1.0 # We are calculating the coefficient\n",
    "\n",
    "            kernel_V_d = kernels_s0['V_d_SS']\n",
    "            kernel_T_d = kernels_s0['T_d_SS']\n",
    "\n",
    "            jump_Vd_val = self._get_jump_value(r_interface, kernel_V_d)\n",
    "            jump_Td_val = self._get_jump_value(r_interface, kernel_T_d)\n",
    "            \n",
    "            V_mat = self.ANGULAR_FACTOR_S0L2 * (r_interface**2 * d_val * jump_Vd_val)\n",
    "            T_mat = self.ANGULAR_FACTOR_S0L2 * (r_interface**2 * d_val * jump_Td_val)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error: Unknown pert_type '{pert_type}'\")\n",
    "            return np.nan\n",
    "\n",
    "        return V_mat - omega_n2_sq * T_mat\n",
    "\n",
    "    def calculate_diagonal_term(self, n, pert_type, pert_profile, omega_n_sq):\n",
    "        \"\"\"\n",
    "        Calculates the diagonal term V_mat(n, n) - omega_n^2 * T_mat(n, n).\n",
    "        This is a convenience wrapper for calculate_coupling_term.\n",
    "        \"\"\"\n",
    "        return self.calculate_coupling_term(n, n, pert_type, pert_profile, omega_n_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc5b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Fisher Matrix Calculator Class\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, pinv\n",
    "import warnings\n",
    "# 'Parallel' and 'delayed' are imported in Cell 1\n",
    "# from joblib import Parallel, delayed \n",
    "\n",
    "class FisherMatrixCalculator:\n",
    "    \"\"\"\n",
    "    Calculates Fisher and Posterior Covariance matrices based on the \n",
    "    SimplifiedS2Calculator results.\n",
    "    \n",
    "    [MODIFIED] Jacobian calculations are parallelized using joblib.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, calculator: SimplifiedS2Calculator, r_obs_meters: float):\n",
    "        \"\"\"\n",
    "        Initializes the Fisher matrix calculator.\n",
    "\n",
    "        Args:\n",
    "            calculator: An initialized instance of SimplifiedS2Calculator.\n",
    "            r_obs_meters: The radial position (in meters) at which amplitudes\n",
    "                          (U, V) are 'observed'.\n",
    "        \"\"\"\n",
    "        if calculator.num_k_modes == 0:\n",
    "            raise ValueError(\"Calculator has no valid modes loaded.\")\n",
    "            \n",
    "        print(f\"--- Initializing FisherMatrixCalculator ---\")\n",
    "        self.calculator = calculator\n",
    "        self.r_model = calculator.r_model\n",
    "        \n",
    "        # Find the index closest to the observation radius\n",
    "        self.r_obs_idx = np.argmin(np.abs(self.r_model - r_obs_meters))\n",
    "        self.r_obs_actual = self.r_model[self.r_obs_idx]\n",
    "        print(f\"Observation radius set to r = {self.r_obs_actual/1e3:.1f} km \"\n",
    "              f\"(requested {r_obs_meters/1e3:.1f} km)\")\n",
    "        \n",
    "        # Store all k_tuples and their omega_sq\n",
    "        self.all_k_tuples = sorted(calculator.k_values_with_data, key=lambda k: k[1])\n",
    "        self.omega_k2_map = calculator.omega_k2_map_instance\n",
    "        \n",
    "        # --- Pre-calculate U_k and V_k at r_obs AND I_k integral ---\n",
    "        print(\"Pre-calculating amplitudes U_k, V_k at observation radius...\")\n",
    "        self.U_at_r_obs = {}\n",
    "        self.V_at_r_obs = {}\n",
    "        \n",
    "        # --- [MODIFICATION (from previous round)] Pre-calculate I_k integral ---\n",
    "        print(f\"Pre-calculating I_k integrals (Integral[ d(mu)/dr * [U_k + C*V_k] * r^2 ] dr)...\")\n",
    "        self.I_k_integral = {}\n",
    "        mu_model = self.calculator.mu_model\n",
    "        r_model = self.calculator.r_model\n",
    "        # Use np.gradient (from numpy) for derivative\n",
    "        dot_mu = np.gradient(mu_model, r_model, edge_order=2) \n",
    "        C_factor = 3.0 / np.sqrt(6.0)\n",
    "        r_sq = r_model**2\n",
    "        # --- [END MODIFICATION] ---\n",
    "        \n",
    "        for k_tuple in self.all_k_tuples:\n",
    "            data = self.calculator.eigen_data[k_tuple]\n",
    "            # U_k is 'u'\n",
    "            u_array = data['u']\n",
    "            # V_k is 'v_div_k' * k_ang (as per _load_single_eigenfunction)\n",
    "            v_array = data['v_div_k'] * self.calculator.k_ang\n",
    "            \n",
    "            self.U_at_r_obs[k_tuple] = u_array[self.r_obs_idx]\n",
    "            self.V_at_r_obs[k_tuple] = v_array[self.r_obs_idx]\n",
    "            \n",
    "            # --- [MODIFICATION (from previous round)] Calculate and store I_k integral ---\n",
    "            # We assume 'simps' is in the global scope (imported in Cell 1)\n",
    "            integrand_I_k = dot_mu * (u_array + C_factor * v_array) * r_sq\n",
    "            self.I_k_integral[k_tuple] = simps(integrand_I_k, r_model)\n",
    "            # --- [END MODIFICATION] ---\n",
    "            \n",
    "        self.k_ang = self.calculator.k_ang # Store for convenience\n",
    "        print(f\"--- FisherMatrixCalculator Initialized ({len(self.all_k_tuples)} modes) ---\\n\")\n",
    "\n",
    "    def _get_valid_n_list(self, n_range):\n",
    "        \"\"\"Filters a given n_range against the modes actually loaded.\"\"\"\n",
    "        valid_n = []\n",
    "        loaded_n_values = {k[1] for k in self.all_k_tuples}\n",
    "        for n in n_range:\n",
    "            if n in loaded_n_values:\n",
    "                valid_n.append(n)\n",
    "            else:\n",
    "                print(f\"Warning: n={n} requested for observable, but not loaded. Skipping.\")\n",
    "        return sorted(list(set(valid_n)))\n",
    "\n",
    "    # --- [MODIFICATION] Parallel Jacobian Helper Methods ---\n",
    "\n",
    "    def _compute_jacobian_F1_column(self, i, n1_list, model_params_m_i):\n",
    "        \"\"\"Computes the i-th column of the G1 Jacobian matrix (for joblib).\"\"\"\n",
    "        pert_type, pert_profile = model_params_m_i[i]\n",
    "        num_n1 = len(n1_list)\n",
    "        column = np.zeros(num_n1)\n",
    "\n",
    "        for j in range(num_n1): # Loop over observables n1\n",
    "            n1 = n1_list[j]\n",
    "            k1_tuple = ('S', n1, self.calculator.l)\n",
    "            omega_n1_sq = self.omega_k2_map[k1_tuple]\n",
    "            \n",
    "            diag_term = self.calculator.calculate_diagonal_term(\n",
    "                n1, pert_type, pert_profile, omega_n1_sq\n",
    "            )\n",
    "            column[j] = diag_term / omega_n1_sq\n",
    "        \n",
    "        return (i, column)\n",
    "\n",
    "    def _compute_jacobian_F2_column(self, i, n2_list, model_params_m_i):\n",
    "        \"\"\"Computes the i-th column of the G2 Jacobian matrix (for joblib).\"\"\"\n",
    "        pert_type, pert_profile = model_params_m_i[i]\n",
    "        num_n2 = len(n2_list)\n",
    "        column = np.zeros(num_n2)\n",
    "        \n",
    "        for j in range(num_n2): # Loop over observables n2\n",
    "            n2 = n2_list[j]\n",
    "            k_n2_tuple = ('S', n2, self.calculator.l)\n",
    "            omega_n2_sq = self.omega_k2_map[k_n2_tuple]\n",
    "            \n",
    "            U_n2_obs = self.U_at_r_obs[k_n2_tuple]\n",
    "            I_n2_integral = self.I_k_integral[k_n2_tuple]\n",
    "            \n",
    "            if abs(U_n2_obs) < 1e-25 or abs(I_n2_integral) < 1e-25:\n",
    "                # print(f\"Warning: U_n(r_obs) or I_n is near-zero for n={n2}. G2(n={n2}, m={i}) set to 0.\")\n",
    "                column[j] = 0.0\n",
    "                continue\n",
    "\n",
    "            sum_term = 0.0\n",
    "            for k_tuple in self.all_k_tuples:\n",
    "                if k_tuple == k_n2_tuple: continue\n",
    "                    \n",
    "                k_n_val = k_tuple[1]\n",
    "                omega_k_sq = self.omega_k2_map[k_tuple]\n",
    "                freq_denom = omega_n2_sq - omega_k_sq\n",
    "                if abs(freq_denom) < 1e-20: continue\n",
    "                    \n",
    "                U_k_obs = self.U_at_r_obs[k_tuple]\n",
    "                I_k_integral_k = self.I_k_integral[k_tuple] # Renamed to avoid confusion\n",
    "                \n",
    "                ratio_U = U_k_obs / U_n2_obs\n",
    "                ratio_I = I_k_integral_k / I_n2_integral\n",
    "                amplitude_ratio = ratio_U + ratio_I\n",
    "                \n",
    "                coupling_term = self.calculator.calculate_coupling_term(\n",
    "                    k_n_val, n2, pert_type, pert_profile, omega_n2_sq\n",
    "                )\n",
    "                sum_term += (1.0 / freq_denom) * amplitude_ratio * coupling_term\n",
    "            \n",
    "            column[j] = sum_term\n",
    "        \n",
    "        return (i, column)\n",
    "\n",
    "    def _compute_jacobian_F3_column(self, i, n3_list, model_params_m_i):\n",
    "        \"\"\"Computes the i-th column of the G3 Jacobian matrix (for joblib).\"\"\"\n",
    "        pert_type, pert_profile = model_params_m_i[i]\n",
    "        num_n3 = len(n3_list)\n",
    "        column = np.zeros(num_n3)\n",
    "        \n",
    "        for j in range(num_n3): # Loop over observables n3\n",
    "            n3 = n3_list[j]\n",
    "            k_n3_tuple = ('S', n3, self.calculator.l)\n",
    "            omega_n3_sq = self.omega_k2_map[k_n3_tuple]\n",
    "            \n",
    "            V_n3_obs = self.V_at_r_obs[k_n3_tuple]\n",
    "            I_n3_integral = self.I_k_integral[k_n3_tuple]\n",
    "            \n",
    "            if abs(V_n3_obs) < 1e-25 or abs(I_n3_integral) < 1e-25:\n",
    "                # print(f\"Warning: V_n(r_obs) or I_n is near-zero for n={n3}. G3(n={n3}, m={i}) set to 0.\")\n",
    "                column[j] = 0.0\n",
    "                continue\n",
    "\n",
    "            sum_term = 0.0\n",
    "            for k_tuple in self.all_k_tuples:\n",
    "                if k_tuple == k_n3_tuple: continue\n",
    "                    \n",
    "                k_n_val = k_tuple[1]\n",
    "                omega_k_sq = self.omega_k2_map[k_tuple]\n",
    "                freq_denom = omega_n3_sq - omega_k_sq\n",
    "                if abs(freq_denom) < 1e-20: continue\n",
    "                    \n",
    "                V_k_obs = self.V_at_r_obs[k_tuple]\n",
    "                I_k_integral_k = self.I_k_integral[k_tuple] # Renamed\n",
    "                \n",
    "                ratio_V = V_k_obs / V_n3_obs\n",
    "                ratio_I = I_k_integral_k / I_n3_integral\n",
    "                amplitude_ratio = ratio_V + ratio_I\n",
    "                \n",
    "                coupling_term = self.calculator.calculate_coupling_term(\n",
    "                    k_n_val, n3, pert_type, pert_profile, omega_n3_sq\n",
    "                )\n",
    "                sum_term += (1.0 / freq_denom) * amplitude_ratio * coupling_term\n",
    "            \n",
    "            column[j] = sum_term\n",
    "            \n",
    "        return (i, column)\n",
    "    \n",
    "    # --- [MODIFICATION] Main Jacobian Build Methods (Now use Parallel) ---\n",
    "\n",
    "    def _build_jacobian_F1(self, n1_list, model_params_m_i):\n",
    "        \"\"\"Builds G1 (Jacobian for F1 - Frequencies) in parallel.\"\"\"\n",
    "        num_n1 = len(n1_list)\n",
    "        num_i = len(model_params_m_i)\n",
    "        G1 = np.zeros((num_n1, num_i))\n",
    "        \n",
    "        if num_n1 == 0:\n",
    "            return G1\n",
    "        \n",
    "        print(f\"Building Jacobian G1 (Frequencies) parallelized over {num_i} parameters...\")\n",
    "        \n",
    "        tasks = [delayed(self._compute_jacobian_F1_column)(i, n1_list, model_params_m_i)\n",
    "                 for i in range(num_i)]\n",
    "        \n",
    "        # Use n_jobs=-1 for all cores\n",
    "        results = Parallel(n_jobs=-1, verbose=5, backend='loky')(tasks)\n",
    "        \n",
    "        for i, column in results:\n",
    "            G1[:, i] = column\n",
    "            \n",
    "        return G1\n",
    "\n",
    "    def _build_jacobian_F2(self, n2_list, model_params_m_i):\n",
    "        \"\"\"Builds G2 (Jacobian for F2 - U-Amplitude) in parallel.\"\"\"\n",
    "        num_n2 = len(n2_list)\n",
    "        num_i = len(model_params_m_i)\n",
    "        G2 = np.zeros((num_n2, num_i))\n",
    "        \n",
    "        if num_n2 == 0:\n",
    "            return G2\n",
    "            \n",
    "        print(f\"Building Jacobian G2 (U-Amplitude) parallelized over {num_i} parameters...\")\n",
    "        \n",
    "        tasks = [delayed(self._compute_jacobian_F2_column)(i, n2_list, model_params_m_i)\n",
    "                 for i in range(num_i)]\n",
    "        \n",
    "        results = Parallel(n_jobs=-1, verbose=5, backend='loky')(tasks)\n",
    "        \n",
    "        for i, column in results:\n",
    "            G2[:, i] = column\n",
    "        \n",
    "        return G2\n",
    "\n",
    "    def _build_jacobian_F3(self, n3_list, model_params_m_i):\n",
    "        \"\"\"Builds G3 (Jacobian for F3 - V-Amplitude) in parallel.\"\"\"\n",
    "        num_n3 = len(n3_list)\n",
    "        num_i = len(model_params_m_i)\n",
    "        G3 = np.zeros((num_n3, num_i))\n",
    "        \n",
    "        if num_n3 == 0:\n",
    "            return G3\n",
    "            \n",
    "        print(f\"Building Jacobian G3 (V-Amplitude) parallelized over {num_i} parameters...\")\n",
    "        \n",
    "        tasks = [delayed(self._compute_jacobian_F3_column)(i, n3_list, model_params_m_i)\n",
    "                 for i in range(num_i)]\n",
    "        \n",
    "        results = Parallel(n_jobs=-1, verbose=5, backend='loky')(tasks)\n",
    "        \n",
    "        for i, column in results:\n",
    "            G3[:, i] = column\n",
    "            \n",
    "        return G3\n",
    "    \n",
    "    # --- [NO CHANGE] Covariance and Fisher Calculation Logic ---\n",
    "    \n",
    "    def _build_cov_matrix_inv(self, num_obs, sigma_val):\n",
    "        \"\"\"Builds a diagonal C_inv = (1/sigma^2) * I\"\"\"\n",
    "        if num_obs == 0 or sigma_val <= 0:\n",
    "            return None # No contribution\n",
    "        \n",
    "        # C = sigma^2 * I  =>  C_inv = (1/sigma^2) * I\n",
    "        C_inv = np.diag(np.full(num_obs, 1.0 / (sigma_val**2)))\n",
    "        return C_inv\n",
    "\n",
    "    def _calculate_fisher_matrix(self, G, C_inv, num_i):\n",
    "        \"\"\"Calculates I = G.T @ C_inv @ G\"\"\"\n",
    "        if C_inv is None or G.shape[0] == 0:\n",
    "            # No observables, so Fisher matrix is zero\n",
    "            return np.zeros((num_i, num_i))\n",
    "        \n",
    "        try:\n",
    "            # I = G.T @ C_inv @ G\n",
    "            I = G.T @ C_inv @ G\n",
    "            return I\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in Fisher matrix calculation (G.T @ C_inv @ G): {e}\")\n",
    "            print(f\"G shape: {G.shape}, C_inv shape: {C_inv.shape}\")\n",
    "            return np.zeros((num_i, num_i))\n",
    "\n",
    "    def calculate_posterior_covariance(self, \n",
    "                                     model_params_m_i,\n",
    "                                     n_range_F1, \n",
    "                                     n_range_F2, \n",
    "                                     n_range_F3,\n",
    "                                     sigma_F1, \n",
    "                                     sigma_F2, \n",
    "                                     sigma_F3,\n",
    "                                     C_prior,\n",
    "                                     combinations_dict):\n",
    "        \"\"\"\n",
    "        Calculates the full posterior covariance matrix for various combinations\n",
    "        of observables.\n",
    "        \"\"\"\n",
    "        \n",
    "        num_i = len(model_params_m_i)\n",
    "        if num_i == 0:\n",
    "            print(\"Error: No model parameters (m_i) defined.\")\n",
    "            return {}\n",
    "            \n",
    "        print(f\"Calculating for {num_i} model parameters (m_i).\")\n",
    "        \n",
    "        # --- Validate observable lists ---\n",
    "        n1_list = self._get_valid_n_list(n_range_F1)\n",
    "        n2_list = self._get_valid_n_list(n_range_F2)\n",
    "        n3_list = self._get_valid_n_list(n_range_F3)\n",
    "        \n",
    "        num_n1 = len(n1_list)\n",
    "        num_n2 = len(n2_list)\n",
    "        num_n3 = len(n3_list)\n",
    "        print(f\"Observables: {num_n1} (F1-Freq), {num_n2} (F2-U_Amp), {num_n3} (F3-V_Amp)\")\n",
    "\n",
    "        # --- Calculate Prior Information Matrix ---\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            I_prior = pinv(C_prior)\n",
    "        \n",
    "        if np.all(I_prior == 0):\n",
    "            print(\"Using uninformative prior (I_prior = 0).\")\n",
    "        else:\n",
    "            print(\"Using informative prior (I_prior = C_prior_inv).\")\n",
    "            \n",
    "        # --- Pre-calculate all Jacobians (NOW IN PARALLEL) ---\n",
    "        G1 = self._build_jacobian_F1(n1_list, model_params_m_i)\n",
    "        G2 = self._build_jacobian_F2(n2_list, model_params_m_i)\n",
    "        G3 = self._build_jacobian_F3(n3_list, model_params_m_i)\n",
    "        \n",
    "        # --- Pre-calculate all C_inv ---\n",
    "        C1_inv = self._build_cov_matrix_inv(num_n1, sigma_F1)\n",
    "        C2_inv = self._build_cov_matrix_inv(num_n2, sigma_F2)\n",
    "        C3_inv = self._build_cov_matrix_inv(num_n3, sigma_F3)\n",
    "\n",
    "        # --- Pre-calculate all Fisher Matrices (I1, I2, I3) ---\n",
    "        print(\"\\nCalculating individual Fisher matrices (I1, I2, I3)...\")\n",
    "        I1 = self._calculate_fisher_matrix(G1, C1_inv, num_i)\n",
    "        I2 = self._calculate_fisher_matrix(G2, C2_inv, num_i)\n",
    "        I3 = self._calculate_fisher_matrix(G3, C3_inv, num_i)\n",
    "        \n",
    "        I_matrices = {'1': I1, '2': I2, '3': I3}\n",
    "        \n",
    "        # --- Calculate C_post for each combination ---\n",
    "        results = {}\n",
    "        print(\"\\nCalculating Posterior Covariance for combinations:\")\n",
    "        \n",
    "        for combo_name, combo_keys in combinations_dict.items():\n",
    "            print(f\"  Combination: '{combo_name}' (Observables: {combo_keys})\")\n",
    "            I_total_obs = np.zeros((num_i, num_i))\n",
    "            \n",
    "            for key in combo_keys:\n",
    "                if key in I_matrices:\n",
    "                    I_total_obs += I_matrices[key]\n",
    "                else:\n",
    "                    print(f\"    Warning: Key '{key}' not in ['1', '2', '3']. Skipping.\")\n",
    "            \n",
    "            # I_post = I_obs + I_prior\n",
    "            I_posterior = I_total_obs + I_prior\n",
    "            \n",
    "            # C_post = (I_post)^-1\n",
    "            try:\n",
    "                C_post = inv(I_posterior)\n",
    "                results[combo_name] = C_post\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(f\"    Error: Posterior Information Matrix for '{combo_name}' is singular.\")\n",
    "                print(\"           This means the parameters are not constrained by this observable set.\")\n",
    "                results[combo_name] = np.full((num_i, num_i), np.inf)\n",
    "\n",
    "        print(\"--- All calculations complete ---\\n\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33f45443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Starting Initialization ---\n",
      "Created output directory: Fisher_Results_Segmented_0n30_1127\n",
      "Attempting to load S-mode frequencies from: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\\res1.txt\n",
      "  Successfully loaded 201 relevant S-mode frequencies.\n",
      "--- Initializing SimplifiedS2Calculator ---\n",
      "Warning: Gravitational constant G is set to 0.0 (matching original code logic).\n",
      "         This means g_model, p_val, and V_rho kernel will be 0.\n",
      "Loading background model from: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\\Reference_Model_8000_code.txt\n",
      "Model loaded: 8000 radial points, R = 1737.1 km\n",
      "\n",
      "Found 201 valid (S, n, 2) modes to process.\n",
      "Preparing all eigenfunction derivatives (S,l=2) (parallelized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 23 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  26 out of 201 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-2)]: Done 197 out of 201 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 201 out of 201 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All 201 (S,l=2) eigenfunctions processed.\n",
      "--- Initialization Complete ---\n",
      "\n",
      "--- 3. Starting Fisher Matrix Calculation ---\n",
      "Generating 54 model parameters (18 segments x 3 types)...\n",
      "--- Initializing FisherMatrixCalculator ---\n",
      "Observation radius set to r = 1737.1 km (requested 1737.1 km)\n",
      "Pre-calculating amplitudes U_k, V_k at observation radius...\n",
      "Pre-calculating I_k integrals (Integral[ d(mu)/dr * [U_k + C*V_k] * r^2 ] dr)...\n",
      "--- FisherMatrixCalculator Initialized (201 modes) ---\n",
      "\n",
      "Calculating for 54 model parameters (m_i).\n",
      "Observables: 30 (F1-Freq), 30 (F2-U_Amp), 30 (F3-V_Amp)\n",
      "Using uninformative prior (I_prior = 0).\n",
      "Building Jacobian G1 (Frequencies) parallelized over 54 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 18 out of 54 | elapsed:    4.5s remaining:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 29 out of 54 | elapsed:    7.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 40 out of 54 | elapsed:    9.8s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 51 out of 54 | elapsed:   12.4s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 54 out of 54 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Jacobian G2 (U-Amplitude) parallelized over 54 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 18 out of 54 | elapsed:    7.9s remaining:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 29 out of 54 | elapsed:   11.4s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 40 out of 54 | elapsed:   14.9s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 51 out of 54 | elapsed:   17.7s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 54 out of 54 | elapsed:   18.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Jacobian G3 (V-Amplitude) parallelized over 54 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 18 out of 54 | elapsed:    7.7s remaining:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 29 out of 54 | elapsed:   10.9s remaining:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 40 out of 54 | elapsed:   14.1s remaining:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 51 out of 54 | elapsed:   17.4s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating individual Fisher matrices (I1, I2, I3)...\n",
      "\n",
      "Calculating Posterior Covariance for combinations:\n",
      "  Combination: 'F1_(Freqs)_Only' (Observables: ['1'])\n",
      "  Combination: 'F1_plus_F3' (Observables: ['1', '3'])\n",
      "  Combination: 'F1_plus_F2_plus_F3' (Observables: ['1', '2', '3'])\n",
      "--- All calculations complete ---\n",
      "\n",
      "\n",
      "--- 4. Processing and Saving Results ---\n",
      "  Saving results for 'F1_(Freqs)_Only' to 'Fisher_Results_Segmented_0n30_1127\\F1_Freqs_Only.txt'\n",
      "  Saving results for 'F1_plus_F3' to 'Fisher_Results_Segmented_0n30_1127\\F1_plus_F3.txt'\n",
      "  Saving results for 'F1_plus_F2_plus_F3' to 'Fisher_Results_Segmented_0n30_1127\\F1_plus_F2_plus_F3.txt'\n",
      "\n",
      "--- All results saved. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 54 out of 54 | elapsed:   17.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Main Execution Block\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "# --- 1. USER: Define All Parameters Here ---\n",
    "\n",
    "# --- 1a.  ---\n",
    "nmin = 0\n",
    "nmax = 30\n",
    "OUTPUT_FOLDER_NAME = \"Fisher_Results_Segmented_\"+str(nmin)+\"n\"+str(nmax)+\"_1127\"\n",
    "FLOAT_PRECISION = 5 # \n",
    "\n",
    "# --- 1b.  (m_i) ---\n",
    "#  (r_min, r_max)\n",
    "# ( delta_rho, delta_kappa, delta_mu )\n",
    "RADIAL_SEGMENTS = [\n",
    "    (0, 100e3),\n",
    "    (100e3, 200e3),\n",
    "    (200e3, 352e3),\n",
    "    (353e3, 480e3),\n",
    "    (481e3, 600e3),\n",
    "    (600e3, 700e3),\n",
    "    (700e3, 800e3),\n",
    "    (800e3, 900e3),\n",
    "    (900e3, 1000e3),\n",
    "    (1000e3, 1100e3),\n",
    "    (1100e3, 1200e3),\n",
    "    (1200e3, 1300e3),\n",
    "    (1300e3, 1400e3),\n",
    "    (1400e3, 1500e3),\n",
    "    (1500e3, 1600e3),\n",
    "    (1600e3, 1709e3),\n",
    "    (1709.1e3, 1725e3), \n",
    "    (1725.1e3, 1737.1e3)\n",
    "]\n",
    "NUM_SEGMENTS = len(RADIAL_SEGMENTS)\n",
    "\n",
    "# --- 1c.  ( Cell 4 ) ---\n",
    "# !! PLEASE UPDATE THESE PATHS !!\n",
    "base_dir = r\"D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\"\n",
    "model_file_path = os.path.join(base_dir, \"Reference_Model_8000_code.txt\")\n",
    "eigen_freq_file_s = os.path.join(base_dir, \"res1.txt\")\n",
    "eigen_func_folder_s = os.path.join(base_dir, \"db25new\")\n",
    "\n",
    "# --- 1d.  ( Cell 4 ) ---\n",
    "N_MIN_SPHER = 0\n",
    "N_MAX_SPHER = 200 #  n=0  200 \n",
    "all_s2_n_values_to_load = list(range(N_MIN_SPHER, N_MAX_SPHER + 1))\n",
    "\n",
    "# --- 1e.  ( Cell 6 ) ---\n",
    "#  Fisher  n  ( 1d )\n",
    "n_range_F1_freqs = range(nmin, nmax)  #  n=0..149 \n",
    "n_range_F2_U_amps = range(nmin, nmax) #  n=0..149  U \n",
    "n_range_F3_V_amps = range(nmin, nmax) #  n=0..149  V \n",
    "\n",
    "#  ()\n",
    "sigma_F1 = 1e-4  # \n",
    "sigma_F2 = 1e-2  # U-\n",
    "sigma_F3 = 1e-2  # V-\n",
    "\n",
    "# --- 1f.  ( Cell 6 ) ---\n",
    "combinations_to_run = {\n",
    "    'F1_(Freqs)_Only': ['1'],\n",
    "    'F1_plus_F3': ['1', '3'],\n",
    "    'F1_plus_F2_plus_F3': ['1', '2', '3']\n",
    "}\n",
    "\n",
    "# --- 1g. ()  ---\n",
    "def _get_model_value(r1, r2, r_model, model_data):\n",
    "    \"\"\"\n",
    "    \n",
    "    ()\n",
    "    \"\"\"\n",
    "    # r\n",
    "    r_mid = (r1 + r2) / 2.0\n",
    "    idx = np.argmin(np.abs(r_model - r_mid))\n",
    "    val = model_data[idx]\n",
    "    if val == 0:\n",
    "        print(f\"Warning: Model value is 0 for segment ({r1/1e3:.1f}-{r2/1e3:.1f} km).\")\n",
    "        return 1e-30 # \n",
    "    return val\n",
    "\n",
    "def _sanitize_filename(name):\n",
    "    \"\"\"\"\"\"\n",
    "    return name.replace(' ', '_').replace('+', 'plus') \\\n",
    "             .replace('(', '').replace(')', '') \\\n",
    "             .replace('/', '').replace('\\\\', '') + \".txt\"\n",
    "\n",
    "\n",
    "# --- 2.  ( Calculator) ---\n",
    "\n",
    "print(\"--- 2. Starting Initialization ---\")\n",
    "try:\n",
    "    # --- 2a.  ---\n",
    "    if not os.path.exists(OUTPUT_FOLDER_NAME):\n",
    "        os.makedirs(OUTPUT_FOLDER_NAME)\n",
    "        print(f\"Created output directory: {OUTPUT_FOLDER_NAME}\")\n",
    "    else:\n",
    "        print(f\"Output directory exists: {OUTPUT_FOLDER_NAME}\")\n",
    "\n",
    "    # --- 2b.  ( Cell 4) ---\n",
    "    full_omega_k2_map_from_file = {}\n",
    "    spher_nl_tuples_to_load = [(n, 2) for n in all_s2_n_values_to_load]\n",
    "    _load_frequencies_from_res1(\n",
    "        res1_path=eigen_freq_file_s, \n",
    "        sigma_char='S', \n",
    "        target_map=full_omega_k2_map_from_file, \n",
    "        nl_tuples_to_consider=spher_nl_tuples_to_load\n",
    "    )\n",
    "\n",
    "    # --- 2c.  SimplifiedS2Calculator ( Cell 4) ---\n",
    "    my_calculator = SimplifiedS2Calculator(\n",
    "        all_s2_n_values=all_s2_n_values_to_load,\n",
    "        model_file=model_file_path,\n",
    "        eigenfunction_folder_spher=eigen_func_folder_s,\n",
    "        omega_k2_map=full_omega_k2_map_from_file,\n",
    "        G_const=0.0 \n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during SETUP: {e}\")\n",
    "    traceback.print_exc()\n",
    "    # \n",
    "    my_calculator = type('obj', (object,), {'num_k_modes': 0})\n",
    "\n",
    "\n",
    "# --- 3.  Fisher  () ---\n",
    "\n",
    "if my_calculator.num_k_modes > 0:\n",
    "    print(\"\\n--- 3. Starting Fisher Matrix Calculation ---\")\n",
    "    try:\n",
    "        # --- 3a.  (m_i) ---\n",
    "        model_params_m_i = []\n",
    "        output_rows_data = [] # \n",
    "        \n",
    "        print(f\"Generating {NUM_SEGMENTS * 3} model parameters ({NUM_SEGMENTS} segments x 3 types)...\")\n",
    "        \n",
    "        for r_min, r_max in RADIAL_SEGMENTS:\n",
    "            # \n",
    "            row_info = {\n",
    "                'r1': r_min, \n",
    "                'r2': r_max,\n",
    "                'model_rho': _get_model_value(r_min, r_max, my_calculator.r_model, my_calculator.rho_model),\n",
    "                'model_kappa': _get_model_value(r_min, r_max, my_calculator.r_model, my_calculator.kappa_model),\n",
    "                'model_mu': _get_model_value(r_min, r_max, my_calculator.r_model, my_calculator.mu_model)\n",
    "            }\n",
    "            output_rows_data.append(row_info)\n",
    "            \n",
    "            #  (rho, kappa, mu) \n",
    "            #  all_std_devs  [std_rho1, std_kappa1, std_mu1, std_rho2, ...]\n",
    "            model_params_m_i.append(('delta_rho', (r_min, r_max)))\n",
    "            model_params_m_i.append(('delta_kappa', (r_min, r_max)))\n",
    "            model_params_m_i.append(('delta_mu', (r_min, r_max)))\n",
    "        \n",
    "        num_i = len(model_params_m_i)\n",
    "        \n",
    "        # --- 3b.  Prior  ---\n",
    "        C_prior = np.zeros((num_i, num_i)) # \n",
    "        r_obs = my_calculator.R_surface    # \n",
    "        \n",
    "        # --- 3c.  FisherMatrixCalculator ---\n",
    "        fisher_calc = FisherMatrixCalculator(my_calculator, r_obs_meters=r_obs)\n",
    "        \n",
    "        # --- 3d.  ---\n",
    "        all_C_post_results = fisher_calc.calculate_posterior_covariance(\n",
    "            model_params_m_i=model_params_m_i,\n",
    "            n_range_F1=n_range_F1_freqs,\n",
    "            n_range_F2=n_range_F2_U_amps,\n",
    "            n_range_F3=n_range_F3_V_amps,\n",
    "            sigma_F1=sigma_F1,\n",
    "            sigma_F2=sigma_F2,\n",
    "            sigma_F3=sigma_F3,\n",
    "            C_prior=C_prior,\n",
    "            combinations_dict=combinations_to_run\n",
    "        )\n",
    "        \n",
    "        # --- 4.  ---\n",
    "        print(\"\\n--- 4. Processing and Saving Results ---\")\n",
    "        \n",
    "        float_format_str = f\"{{:.{FLOAT_PRECISION}e}}\" # e.g., \"{:.6e}\"\n",
    "        \n",
    "        for combo_name, C_post in all_C_post_results.items():\n",
    "            \n",
    "            output_filepath = os.path.join(OUTPUT_FOLDER_NAME, _sanitize_filename(combo_name))\n",
    "            print(f\"  Saving results for '{combo_name}' to '{output_filepath}'\")\n",
    "            \n",
    "            # \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                # all_std_devs  3*x \n",
    "                all_std_devs = np.sqrt(np.diag(C_post))\n",
    "            \n",
    "            with open(output_filepath, 'w') as f:\n",
    "                # \n",
    "                header = (\n",
    "                    f\"#{'r1(km)':<8} {'r2(km)':<8} \"\n",
    "                    f\"{'std_rho':<15} {'std_kappa':<15} {'std_mu':<15} \"\n",
    "                    f\"{'std_rho/rho':<15} {'std_kappa/kappa':<15} {'std_mu/mu':<15}\\n\"\n",
    "                )\n",
    "                f.write(header)\n",
    "                \n",
    "                # \n",
    "                for i in range(NUM_SEGMENTS):\n",
    "                    #  std_devs  (rho, kappa, mu) \n",
    "                    std_rho   = all_std_devs[i*3 + 0]\n",
    "                    std_kappa = all_std_devs[i*3 + 1]\n",
    "                    std_mu    = all_std_devs[i*3 + 2]\n",
    "                    \n",
    "                    #  (r1, r2, model_values)\n",
    "                    seg_info = output_rows_data[i]\n",
    "                    \n",
    "                    # \n",
    "                    norm_std_rho = std_rho / seg_info['model_rho']\n",
    "                    norm_std_kappa = std_kappa / seg_info['model_kappa']\n",
    "                    norm_std_mu = std_mu / seg_info['model_mu']\n",
    "                    \n",
    "                    # \n",
    "                    r1_str = f\"{seg_info['r1'] / 1e3:<8.1f}\"\n",
    "                    r2_str = f\"{seg_info['r2'] / 1e3:<8.1f}\"\n",
    "                    \n",
    "                    std_rho_str   = f\"{float_format_str.format(std_rho):<15}\"\n",
    "                    std_kappa_str = f\"{float_format_str.format(std_kappa):<15}\"\n",
    "                    std_mu_str    = f\"{float_format_str.format(std_mu):<15}\"\n",
    "                    \n",
    "                    norm_rho_str   = f\"{float_format_str.format(norm_std_rho):<15}\"\n",
    "                    norm_kappa_str = f\"{float_format_str.format(norm_std_kappa):<15}\"\n",
    "                    norm_mu_str    = f\"{float_format_str.format(norm_std_mu):<15}\"\n",
    "                    \n",
    "                    # \n",
    "                    f.write(\n",
    "                        f\"{r1_str} {r2_str} \"\n",
    "                        f\"{std_rho_str} {std_kappa_str} {std_mu_str} \"\n",
    "                        f\"{norm_rho_str} {norm_kappa_str} {norm_mu_str}\\n\"\n",
    "                    )\n",
    "\n",
    "        print(\"\\n--- All results saved. ---\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during CALCULATION: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"\\n'my_calculator' instance not found or is empty.\")\n",
    "    print(\"Please check initialization steps (Cell 3) and file paths (Cell 5).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
