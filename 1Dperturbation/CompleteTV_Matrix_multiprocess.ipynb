{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f8c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import simps, cumulative_trapezoid\n",
    "from scipy.constants import G as Const_G # Gravitational constant (SI units)\n",
    "import os\n",
    "import warnings\n",
    "import sys # For flushing output in loops\n",
    "from sympy import N\n",
    "from sympy.physics.wigner import wigner_3j\n",
    "import math\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed # For parallelization\n",
    "import functools # Added for lru_cache\n",
    "\n",
    "# Suppress RuntimeWarnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in true_divide')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='divide by zero encountered in true_divide')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in power')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='divide by zero encountered in power')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in multiply')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in subtract')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='invalid value encountered in cast') # For float(N(sympy_val))\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='Numerical coinsidence while calculating wigner symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef3604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Top-level caches and functions\n",
    "# --- Top-level manual caches ---\n",
    "_wigner_3j_cache_dict = {}\n",
    "_b_factor_cache_dict = {}\n",
    "\n",
    "# --- Top-level cached Wigner and B-factor functions ---\n",
    "def _wigner_3j_sym_top_level_manual_cache(j1, j2, j3, m1, m2, m3):\n",
    "    args = (j1, j2, j3, m1, m2, m3)\n",
    "    if args in _wigner_3j_cache_dict:\n",
    "        return _wigner_3j_cache_dict[args]\n",
    "    \n",
    "    val = wigner_3j(j1, j2, j3, m1, m2, m3)\n",
    "    result = 0.0\n",
    "    if val is not None:\n",
    "        try:\n",
    "            result = float(N(val))\n",
    "        except TypeError:\n",
    "            result = float(val)\n",
    "    _wigner_3j_cache_dict[args] = result\n",
    "    return result\n",
    "\n",
    "def _calculate_B_factor_top_level_manual_cache(l1_in, s_in, l2_in, N_in, sign_pm):\n",
    "    args = (l1_in, s_in, l2_in, N_in, sign_pm)\n",
    "    if args in _b_factor_cache_dict:\n",
    "        return _b_factor_cache_dict[args]\n",
    "\n",
    "    if not (abs(l1_in - s_in) <= l2_in <= (l1_in + s_in)):\n",
    "        _b_factor_cache_dict[args] = 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    term_parity_val = 1.0\n",
    "    if sign_pm == 1: term_parity_val = 1.0 + (-1)**(l1_in + s_in + l2_in)\n",
    "    elif sign_pm == -1: term_parity_val = 1.0 - (-1)**(l1_in + s_in + l2_in)\n",
    "    else: raise ValueError(\"sign_pm must be +1 or -1\")\n",
    "    \n",
    "    if abs(term_parity_val) < 1e-9:\n",
    "        _b_factor_cache_dict[args] = 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    N_in_int = int(N_in)\n",
    "    try:\n",
    "        math.factorial(l1_in + N_in_int)\n",
    "        math.factorial(l2_in + N_in_int)\n",
    "        if (l1_in - N_in_int) < 0 or (l2_in - N_in_int) < 0 :\n",
    "            _b_factor_cache_dict[args] = 0.0\n",
    "            return 0.0\n",
    "        sqrt_term_num_val = math.factorial(l1_in + N_in_int) * math.factorial(l2_in + N_in_int)\n",
    "        sqrt_term_den_val = math.factorial(l1_in - N_in_int) * math.factorial(l2_in - N_in_int)\n",
    "    except ValueError: \n",
    "        _b_factor_cache_dict[args] = 0.0\n",
    "        return 0.0\n",
    "\n",
    "    if abs(sqrt_term_den_val) < 1e-30: \n",
    "        if abs(sqrt_term_num_val) < 1e-30:\n",
    "            _b_factor_cache_dict[args] = 0.0\n",
    "            return 0.0\n",
    "        _b_factor_cache_dict[args] = np.inf\n",
    "        return np.inf\n",
    "            \n",
    "    sqrt_val_num = np.sqrt(sqrt_term_num_val / sqrt_term_den_val)\n",
    "    w3j_val = _wigner_3j_sym_top_level_manual_cache(l1_in, s_in, l2_in, -N_in_int, 0, N_in_int)\n",
    "    \n",
    "    if abs(w3j_val) < 1e-15:\n",
    "        _b_factor_cache_dict[args] = 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    result = 0.5 * ((-1)**N_in_int) * term_parity_val * sqrt_val_num * w3j_val\n",
    "    _b_factor_cache_dict[args] = result\n",
    "    return result\n",
    "\n",
    "# --- Top-level function for perturbation coefficients ---\n",
    "def _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "    perturbations_direct_coeffs_arg, \n",
    "    pert_type, s, t_complex_target, r_values_or_scalar\n",
    "):\n",
    "    is_scalar_request = isinstance(r_values_or_scalar, (int, float, np.floating))\n",
    "    def fetch_user_input_coeff(current_pert_type, current_s, current_t_input, current_r_val_or_scalar):\n",
    "        if current_pert_type == 'delta_d':\n",
    "            if not isinstance(current_r_val_or_scalar, (int, float, np.floating)):\n",
    "                raise ValueError(\"r_values_or_scalar must be a scalar for delta_d in fetch_user_input_coeff\")\n",
    "            interface_radius = float(current_r_val_or_scalar)\n",
    "            val = perturbations_direct_coeffs_arg.get(current_pert_type, {}).get(\\\n",
    "                (interface_radius, current_s, current_t_input), 0.0 )\n",
    "            return float(val)\n",
    "        else: \n",
    "            pert_data = perturbations_direct_coeffs_arg.get(current_pert_type, {}).get(\\\n",
    "                (current_s, current_t_input), None )\n",
    "            if isinstance(current_r_val_or_scalar, (int, float, np.floating)):\n",
    "                r_arr = np.array([float(current_r_val_or_scalar)], dtype=float)\n",
    "                is_scalar_r_loc = True\n",
    "            else:\n",
    "                r_arr = np.asarray(current_r_val_or_scalar, dtype=float)\n",
    "                is_scalar_r_loc = False\n",
    "            val_arr = np.zeros_like(r_arr, dtype=float)\n",
    "            if pert_data is None: pass\n",
    "            elif callable(pert_data): val_arr = np.array(pert_data(r_arr), dtype=float)\n",
    "            elif isinstance(pert_data, (int, float, np.floating)): val_arr = np.full_like(r_arr, float(pert_data), dtype=float)\n",
    "            elif isinstance(pert_data, dict) and 'value' in pert_data and 'range' in pert_data:\n",
    "                v_pert = float(pert_data['value']); r_min, r_max = pert_data['range']\n",
    "                mask = (r_arr >= r_min) & (r_arr <= r_max); val_arr[mask] = v_pert\n",
    "            elif isinstance(pert_data, np.ndarray) and pert_data.shape == r_arr.shape: val_arr = pert_data.astype(float)\n",
    "            else: print(f\"Warning: Invalid format for volumetric perturbation {current_pert_type} ({current_s},{current_t_input}). Returning zeros.\")\n",
    "            return val_arr[0] if is_scalar_r_loc else val_arr\n",
    "    \n",
    "    if t_complex_target == 0:\n",
    "        m_s0_input = fetch_user_input_coeff(pert_type, s, 0, r_values_or_scalar)\n",
    "        return np.asarray(m_s0_input * np.sqrt(4*np.pi), dtype=complex) \n",
    "    \n",
    "    tau = abs(t_complex_target)\n",
    "    m_s_neg_tau_input = fetch_user_input_coeff(pert_type, s, -tau, r_values_or_scalar) \n",
    "    m_s_pos_tau_input = fetch_user_input_coeff(pert_type, s, tau, r_values_or_scalar)  \n",
    "\n",
    "    re_m_tilde_s_tau = m_s_neg_tau_input / np.sqrt(2.0) \n",
    "    im_m_tilde_s_tau = -m_s_pos_tau_input / np.sqrt(2.0) \n",
    "    \n",
    "    m_tilde_s_tau_calculated = re_m_tilde_s_tau + 1j * im_m_tilde_s_tau\n",
    "    \n",
    "    if t_complex_target > 0: \n",
    "        return np.asarray(m_tilde_s_tau_calculated  * np.sqrt(4*np.pi), dtype=complex)\n",
    "    else: \n",
    "        sign_factor = 1 if tau % 2 == 0 else -1  \n",
    "        m_tilde_s_neg_tau_calculated = sign_factor * np.conjugate(m_tilde_s_tau_calculated  * np.sqrt(4*np.pi))\n",
    "        return np.asarray(m_tilde_s_neg_tau_calculated, dtype=complex)\n",
    "\n",
    "# --- Top-level function for kernels ---\n",
    "def _calculate_kernels_top_level(\n",
    "    k1_tuple, k2_tuple, # For l1, l2, s1_char, s2_char\n",
    "    data_k1, data_k2, s_pert, \n",
    "    rho_model_tl, g_model_tl, kappa_model_tl, mu_model_tl, r_stable_tl, # model arrays\n",
    "    G_const_tl # Gravitational constant\n",
    "):\n",
    "    s1_char, n1, l1 = k1_tuple \n",
    "    s2_char, n2, l2 = k2_tuple \n",
    "    kernels = {}\n",
    "\n",
    "    B0_plus  = _calculate_B_factor_top_level_manual_cache(l1, s_pert, l2, 0, +1)\n",
    "    B1_plus  = _calculate_B_factor_top_level_manual_cache(l1, s_pert, l2, 1, +1)\n",
    "    B1_minus = _calculate_B_factor_top_level_manual_cache(l1, s_pert, l2, 1, -1)\n",
    "    B2_plus  = _calculate_B_factor_top_level_manual_cache(l1, s_pert, l2, 2, +1)\n",
    "    B2_minus = _calculate_B_factor_top_level_manual_cache(l1, s_pert, l2, 2, -1)\n",
    "    \n",
    "    B_l2_l1_s_1_plus  = _calculate_B_factor_top_level_manual_cache(l2, l1, s_pert, 1, +1)\n",
    "    B_l2_l1_s_1_minus = _calculate_B_factor_top_level_manual_cache(l2, l1, s_pert, 1, -1)\n",
    "\n",
    "    B_l1_l2_s_1_plus  = _calculate_B_factor_top_level_manual_cache(l1, l2, s_pert, 1, +1)\n",
    "    B_l1_l2_s_1_minus = _calculate_B_factor_top_level_manual_cache(l1, l2, s_pert, 1, -1)\n",
    "\n",
    "    if s1_char == 'S' and s2_char == 'S':\n",
    "        u1,v1dk,du1,f1,x1,p1,dp1 = data_k1['u'],data_k1['v_div_k'],data_k1['dot_u'],data_k1['f_val'],data_k1['x_val'],data_k1['p_val'],data_k1['dot_p']\n",
    "        u2,v2dk,du2,f2,x2,p2,dp2 = data_k2['u'],data_k2['v_div_k'],data_k2['dot_u'],data_k2['f_val'],data_k2['x_val'],data_k2['p_val'],data_k2['dot_p']\n",
    "        \n",
    "        kernels['T_rho_SS'] = u1*u2*B0_plus + v1dk*v2dk*B1_plus \n",
    "        kernels['V_kappa_SS'] = (du1+f1)*(du2+f2)*B0_plus\n",
    "        \n",
    "        V_mu_SS_term1 = (1./3.)*(2*du1-f1)*(2*du2-f2)*B0_plus\n",
    "        V_mu_SS_term2 = x1*x2*B1_plus\n",
    "        V_mu_SS_term3 = np.divide(v1dk*v2dk, r_stable_tl**2, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0))*B2_plus\n",
    "        kernels['V_mu_SS'] = V_mu_SS_term1 + V_mu_SS_term2 + V_mu_SS_term3\n",
    "\n",
    "        V_rho_SS_term1 = (u1*dp2 + dp1*u2 - 0.5*g_model_tl * \\\n",
    "                         (np.divide(4*u1*u2,r_stable_tl,out=np.zeros_like(rho_model_tl),where=r_stable_tl!=0) + f1*u2 + u1*f2) + \\\n",
    "                         8*np.pi*G_const_tl*rho_model_tl*u1*u2)*B0_plus\n",
    "        V_rho_SS_term2 = np.divide((p1*v2dk + v1dk*p2) + 0.5*g_model_tl*(u1*v2dk + v1dk*u2), \\\n",
    "                                 r_stable_tl, out=np.zeros_like(rho_model_tl), where=r_stable_tl!=0)*B1_plus\n",
    "        kernels['V_rho_SS'] = V_rho_SS_term1 + V_rho_SS_term2\n",
    "        \n",
    "        Vd_SS_term_bg = -kappa_model_tl*kernels['V_kappa_SS'] - mu_model_tl*kernels['V_mu_SS'] - rho_model_tl*kernels['V_rho_SS']\n",
    "        Vd_SS_kappa_deriv = kappa_model_tl*( \\\n",
    "                                      (2*du1*du2 + du1*f2 + f1*du2)*B0_plus \\\n",
    "                                      - np.divide((du1+f1)*v2dk, r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l2_l1_s_1_plus \n",
    "                                      - np.divide(v1dk*(du2+f2), r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l1_l2_s_1_plus  \n",
    "                                      )\n",
    "        Vd_SS_mu_deriv = mu_model_tl*( \\\n",
    "                                    (2./3.)*(4*du1*du2 - du1*f2 - f1*du2)*B0_plus \\\n",
    "                                    + (data_k1['dot_v_div_k']*x2 + x1*data_k2['dot_v_div_k'])*B1_plus \\\n",
    "                                    - (2./3.)*np.divide((2*du1-f1)*v2dk, r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l2_l1_s_1_plus \\\n",
    "                                    - (2./3.)*np.divide(v1dk*(2*du2-f2), r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l1_l2_s_1_plus \\\n",
    "                                    )\n",
    "        kernels['V_d_SS'] = Vd_SS_term_bg + Vd_SS_kappa_deriv + Vd_SS_mu_deriv\n",
    "    elif s1_char == 'T' and s2_char == 'T':\n",
    "        w1dk, dw1dk, z1 = data_k1['w_div_k'], data_k1['dot_w_div_k'], data_k1['z_val']\n",
    "        w2dk, dw2dk, z2 = data_k2['w_div_k'], data_k2['dot_w_div_k'], data_k2['z_val']\n",
    "        kernels['T_rho_TT'] = w1dk*w2dk*B1_plus \n",
    "        kernels['V_kappa_TT'] = np.zeros_like(rho_model_tl)\n",
    "        V_mu_TT_term1 = z1*z2*B1_plus\n",
    "        V_mu_TT_term2 = np.divide(w1dk*w2dk, r_stable_tl**2, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0))*B2_plus\n",
    "        kernels['V_mu_TT'] = V_mu_TT_term1 + V_mu_TT_term2\n",
    "        kernels['V_rho_TT'] = np.zeros_like(rho_model_tl)\n",
    "        Vd_TT_term_bg = -mu_model_tl*kernels['V_mu_TT'] \n",
    "        Vd_TT_mu_deriv = mu_model_tl*(dw1dk*z2 + z1*dw2dk)*B1_plus \n",
    "        kernels['V_d_TT'] = Vd_TT_term_bg + Vd_TT_mu_deriv\n",
    "    elif s1_char == 'S' and s2_char == 'T': \n",
    "        u1,v1dk,du1,f1,x1,p1,dv1dk = data_k1['u'],data_k1['v_div_k'],data_k1['dot_u'],data_k1['f_val'],data_k1['x_val'],data_k1['p_val'],data_k1['dot_v_div_k']\n",
    "        w2dk, dw2dk, z2 = data_k2['w_div_k'], data_k2['dot_w_div_k'], data_k2['z_val']\n",
    "        kernels['T_rho_ST'] = -1j*v1dk*w2dk*B1_minus\n",
    "        kernels['V_kappa_ST'] = np.zeros_like(rho_model_tl)\n",
    "        V_mu_ST_term1 = -1j*x1*z2*B1_minus\n",
    "        V_mu_ST_term2 = -1j*np.divide(v1dk*w2dk, r_stable_tl**2, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0))*B2_minus\n",
    "        kernels['V_mu_ST'] = V_mu_ST_term1 + V_mu_ST_term2\n",
    "        kernels['V_rho_ST'] = -1j*np.divide(p1*w2dk + 0.5*g_model_tl*u1*w2dk, r_stable_tl, out=np.zeros_like(rho_model_tl), where=r_stable_tl!=0)*B1_minus\n",
    "        Vd_ST_term_bg = -mu_model_tl*kernels['V_mu_ST'] - rho_model_tl*kernels['V_rho_ST']\n",
    "        Vd_ST_kappa_deriv = -kappa_model_tl * (1j * np.divide((du1+f1)*w2dk, r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l2_l1_s_1_minus ) \n",
    "        Vd_ST_mu_deriv = mu_model_tl * ( -(dv1dk*z2 + x1*dw2dk)*B1_minus \\\n",
    "                                         - (2./3.) * (1j * np.divide((2*du1-f1)*w2dk, r_stable_tl, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0)) * B_l2_l1_s_1_minus) )\n",
    "        kernels['V_d_ST'] = Vd_ST_term_bg + Vd_ST_kappa_deriv + Vd_ST_mu_deriv\n",
    "    elif s1_char == 'T' and s2_char == 'S': \n",
    "        w1dk, dw1dk, z1 = data_k1['w_div_k'], data_k1['dot_w_div_k'], data_k1['z_val']\n",
    "        u2,v2dk,du2,f2,x2,p2,dv2dk = data_k2['u'],data_k2['v_div_k'],data_k2['dot_u'],data_k2['f_val'],data_k2['x_val'],data_k2['p_val'],data_k2['dot_v_div_k']\n",
    "        kernels['T_rho_TS'] = 1j*w1dk*v2dk*B1_minus\n",
    "        kernels['V_kappa_TS'] = np.zeros_like(rho_model_tl)\n",
    "        V_mu_TS_term1 = 1j*z1*x2*B1_minus\n",
    "        V_mu_TS_term2 = 1j*np.divide(w1dk*v2dk, r_stable_tl**2, out=np.zeros_like(rho_model_tl), where=(r_stable_tl!=0))*B2_minus\n",
    "        kernels['V_mu_TS'] = V_mu_TS_term1 + V_mu_TS_term2\n",
    "        kernels['V_rho_TS'] = 1j*np.divide(w1dk*p2 + 0.5*g_model_tl*w1dk*u2, r_stable_tl, out=np.zeros_like(rho_model_tl), where=r_stable_tl!=0)*B1_minus\n",
    "        Vd_TS_term_bg = -mu_model_tl*kernels['V_mu_TS'] - rho_model_tl*kernels['V_rho_TS']\n",
    "        Vd_TS_kappa_deriv = kappa_model_tl * (1j * np.divide(w1dk*(du2+f2), r_stable_tl, out=np.zeros_like(rho_model_tl), where=r_stable_tl!=0) * B_l1_l2_s_1_minus )\n",
    "        Vd_TS_mu_deriv = mu_model_tl * ( (z1*dv2dk + dw1dk*x2)*B1_minus \\\n",
    "                                       + (2./3.) * (1j * np.divide(w1dk*(2*du2-f2), r_stable_tl, out=np.zeros_like(rho_model_tl), where=r_stable_tl!=0) * B_l1_l2_s_1_minus) )\n",
    "        kernels['V_d_TS'] = Vd_TS_term_bg + Vd_TS_kappa_deriv + Vd_TS_mu_deriv\n",
    "\n",
    "    for coupling_type_td in ['SS', 'TT', 'ST', 'TS']:\n",
    "        if f'T_rho_{coupling_type_td}' in kernels:\n",
    "             kernels[f'T_d_{coupling_type_td}'] = -rho_model_tl * kernels[f'T_rho_{coupling_type_td}']\n",
    "    return kernels\n",
    "\n",
    "# --- Main top-level task function for parallel execution ---\n",
    "def _calculate_k1k2_tilde_block_job_top_level(\n",
    "    k1_tuple_job, k2_tuple_job,\n",
    "    data_k1, data_k2, \n",
    "    r_model_tl, rho_model_tl, g_model_tl, kappa_model_tl, mu_model_tl, r_stable_tl, \n",
    "    G_const_tl,\n",
    "    perturbations_direct_coeffs_arg,\n",
    "    s_max_arg,\n",
    "    l1_job, l2_job, \n",
    "    m_values_l1, m_values_l2, matrix_size_l1m, matrix_size_l2m\n",
    "):\n",
    "    s1_char_job, _, _ = k1_tuple_job\n",
    "    s2_char_job, _, _ = k2_tuple_job\n",
    "    coupling_type_job = f\"{s1_char_job}{s2_char_job}\"\n",
    "\n",
    "    V_tilde_block = np.zeros((matrix_size_l1m, matrix_size_l2m), dtype=complex)\n",
    "    T_tilde_block = np.zeros((matrix_size_l1m, matrix_size_l2m), dtype=complex)\n",
    "\n",
    "    for s_pert in range(s_max_arg + 1): \n",
    "        if not (abs(l1_job - s_pert) <= l2_job <= (l1_job + s_pert)): continue\n",
    "        \n",
    "        kernels_r_s = _calculate_kernels_top_level(\n",
    "            k1_tuple_job, k2_tuple_job, data_k1, data_k2, s_pert,\n",
    "            rho_model_tl, g_model_tl, kappa_model_tl, mu_model_tl, r_stable_tl, G_const_tl\n",
    "        )\n",
    "        #if f'T_rho_{coupling_type_job}' not in kernels_r_s: continue \n",
    "        \n",
    "        relevant_interface_radii_for_s_pert_d = []\n",
    "        if 'delta_d' in perturbations_direct_coeffs_arg:\n",
    "            relevant_interface_radii_for_s_pert_d = sorted(list(set(\\\n",
    "                k_pert_key[0] for k_pert_key in perturbations_direct_coeffs_arg['delta_d'].keys()\\\n",
    "                if k_pert_key[1] == s_pert )))\n",
    "        \n",
    "        for t_complex in range(-s_pert, s_pert + 1):\n",
    "            delta_rho_st_tilde_r = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                perturbations_direct_coeffs_arg, 'delta_rho', s_pert, t_complex, r_model_tl)\n",
    "            is_rho_pert_present = np.any(np.abs(delta_rho_st_tilde_r) > 1e-20)\n",
    "\n",
    "            delta_mu_st_tilde_r = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                perturbations_direct_coeffs_arg, 'delta_mu', s_pert, t_complex, r_model_tl)\n",
    "            is_mu_pert_present = np.any(np.abs(delta_mu_st_tilde_r) > 1e-20)\n",
    "\n",
    "            delta_kappa_st_tilde_r = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                perturbations_direct_coeffs_arg, 'delta_kappa', s_pert, t_complex, r_model_tl)\n",
    "            is_kappa_pert_present = np.any(np.abs(delta_kappa_st_tilde_r) > 1e-20)\n",
    "            \n",
    "            is_d_pert_present = False\n",
    "            if relevant_interface_radii_for_s_pert_d:\n",
    "                for d_i_check in relevant_interface_radii_for_s_pert_d:\n",
    "                    d_pert_val_for_st = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                        perturbations_direct_coeffs_arg, 'delta_d', s_pert, t_complex, d_i_check)\n",
    "                    if abs(d_pert_val_for_st) > 1e-20: is_d_pert_present = True; break\n",
    "            if not (is_rho_pert_present or is_d_pert_present or is_mu_pert_present or is_kappa_pert_present): continue\n",
    "\n",
    "            kernel_T_rho = kernels_r_s[f'T_rho_{coupling_type_job}']\n",
    "            kernel_T_d = kernels_r_s.get(f'T_d_{coupling_type_job}', np.zeros_like(r_model_tl))\n",
    "            kernel_V_rho = kernels_r_s[f'V_rho_{coupling_type_job}']\n",
    "            kernel_V_mu = kernels_r_s[f'V_mu_{coupling_type_job}']\n",
    "            kernel_V_kappa = kernels_r_s[f'V_kappa_{coupling_type_job}']\n",
    "            kernel_V_d = kernels_r_s.get(f'V_d_{coupling_type_job}', np.zeros_like(r_model_tl))\n",
    "            \n",
    "            integral_T_rho_val = 0.0j\n",
    "            if is_rho_pert_present: \n",
    "                integral_T_rho_val = simps(delta_rho_st_tilde_r * kernel_T_rho * r_model_tl**2, r_model_tl)\n",
    "            \n",
    "            boundary_sum_T_d_val = 0.0j\n",
    "            if is_d_pert_present:\n",
    "                for d_i_interface in relevant_interface_radii_for_s_pert_d:\n",
    "                    delta_d_st_tilde_scalar = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                        perturbations_direct_coeffs_arg, 'delta_d', s_pert, t_complex, d_i_interface)\n",
    "                    \n",
    "                    if abs(delta_d_st_tilde_scalar) > 1e-20:\n",
    "                        # --- START of MODIFICATION ---\n",
    "                        surface_proximity_threshold = 500.0  # 定义星球外表面附近的范围 (单位: m)\n",
    "                        R_surface = r_model_tl[-1]\n",
    "                        jump_Td_val = 0.0j  # 初始化跳变值\n",
    "\n",
    "                        # 检查边界是否在星球外表面附近\n",
    "                        if abs(d_i_interface - R_surface) < surface_proximity_threshold:\n",
    "                            # 是表面微扰：跳变值为 0 - 表面值\n",
    "                            # kernel_T_d 数组的最后一个元素即为星球表面值\n",
    "                            jump_Td_val = 0.0 - kernel_T_d[-1]\n",
    "                        else:\n",
    "                            # 是内部界面微扰：使用原始的上下界面求差逻辑\n",
    "                            jump_half_width = 500\n",
    "                            idx_below_arr = np.where(r_model_tl < (d_i_interface - jump_half_width))[0]\n",
    "                            idx_above_arr = np.where(r_model_tl >= (d_i_interface + jump_half_width))[0]\n",
    "                            if len(idx_below_arr) > 0 and len(idx_above_arr) > 0:\n",
    "                                idx_b, idx_a = idx_below_arr[-1], idx_above_arr[0]\n",
    "                                if idx_b < idx_a and idx_a < len(r_model_tl):\n",
    "                                    jump_Td_val = kernel_T_d[idx_a] - kernel_T_d[idx_b]\n",
    "                        \n",
    "                        # 根据计算出的跳变值累加\n",
    "                        boundary_sum_T_d_val += d_i_interface**2 * delta_d_st_tilde_scalar * jump_Td_val\n",
    "            sum_contrib_T_val = integral_T_rho_val + boundary_sum_T_d_val\n",
    "            \n",
    "            integral_V_rho_val = 0.0j\n",
    "            if is_rho_pert_present: \n",
    "                integral_V_rho_val = simps(delta_rho_st_tilde_r * kernel_V_rho * r_model_tl**2, r_model_tl)\n",
    "            integral_V_mu_val = 0.0j\n",
    "            if is_mu_pert_present: \n",
    "                integral_V_mu_val = simps(delta_mu_st_tilde_r * kernel_V_mu * r_model_tl**2, r_model_tl)\n",
    "            integral_V_kappa_val = 0.0j\n",
    "            if is_kappa_pert_present: \n",
    "                integral_V_kappa_val = simps(delta_kappa_st_tilde_r * kernel_V_kappa * r_model_tl**2, r_model_tl)\n",
    "            boundary_sum_V_d_val = 0.0j\n",
    "            if is_d_pert_present:\n",
    "                for d_i_interface in relevant_interface_radii_for_s_pert_d:\n",
    "                    delta_d_st_tilde_scalar = _get_tilde_perturbation_coeff_from_direct_input_top_level(\n",
    "                        perturbations_direct_coeffs_arg, 'delta_d', s_pert, t_complex, d_i_interface)\n",
    "\n",
    "                    if abs(delta_d_st_tilde_scalar) > 1e-20:\n",
    "                        # --- START of MODIFICATION ---\n",
    "                        surface_proximity_threshold = 500.0  # 定义星球外表面附近的范围 (单位: m)\n",
    "                        R_surface = r_model_tl[-1]\n",
    "                        jump_Vd_val = 0.0j  # 初始化跳变值\n",
    "                        \n",
    "                        # 检查边界是否在星球外表面附近\n",
    "                        if abs(d_i_interface - R_surface) < surface_proximity_threshold:\n",
    "                            # 是表面微扰：跳变值为 0 - 表面值\n",
    "                            # kernel_V_d 数组的最后一个元素即为星球表面值\n",
    "                            jump_Vd_val = 0.0 - kernel_V_d[-1]\n",
    "                        else:\n",
    "                            # 是内部界面微扰：使用原始的上下界面求差逻辑\n",
    "                            jump_half_width = 50\n",
    "                            idx_below_arr = np.where(r_model_tl < (d_i_interface - jump_half_width))[0]\n",
    "                            idx_above_arr = np.where(r_model_tl >= (d_i_interface + jump_half_width))[0]\n",
    "                            if len(idx_below_arr) > 0 and len(idx_above_arr) > 0:\n",
    "                                idx_b, idx_a = idx_below_arr[-1], idx_above_arr[0]\n",
    "                                if idx_b < idx_a and idx_a < len(r_model_tl):\n",
    "                                    jump_Vd_val = kernel_V_d[idx_a] - kernel_V_d[idx_b]\n",
    "\n",
    "                        # 根据计算出的跳变值累加\n",
    "                        boundary_sum_V_d_val += d_i_interface**2 * delta_d_st_tilde_scalar * jump_Vd_val\n",
    "            sum_contrib_V_val = integral_V_rho_val + integral_V_mu_val + integral_V_kappa_val + boundary_sum_V_d_val\n",
    "            \n",
    "            if abs(sum_contrib_T_val) < 1e-20 and abs(sum_contrib_V_val) < 1e-20: continue\n",
    "            \n",
    "            common_3j_prefactor = np.sqrt( (2*l1_job+1) * (2*s_pert+1) * (2*l2_job+1) / (4*np.pi) )\n",
    "            \n",
    "            for m1_idx_loop, m1_val_orig in enumerate(m_values_l1):\n",
    "                m1_val_loop = int(m1_val_orig) \n",
    "                for m2_idx_loop, m2_val_orig in enumerate(m_values_l2):\n",
    "                    m2_val_loop = int(m2_val_orig) \n",
    "                    \n",
    "                    w3j_symbol_val = _wigner_3j_sym_top_level_manual_cache(l1_job, s_pert, l2_job, -m1_val_loop, t_complex, m2_val_loop)\n",
    "                    if abs(w3j_symbol_val) < 1e-15: continue\n",
    "                    \n",
    "                    sign_m1_term = (-1)**m1_val_loop \n",
    "                    final_angular_factor = sign_m1_term * common_3j_prefactor * w3j_symbol_val\n",
    "                    \n",
    "                    T_tilde_block[m1_idx_loop, m2_idx_loop] += final_angular_factor * sum_contrib_T_val\n",
    "                    V_tilde_block[m1_idx_loop, m2_idx_loop] += final_angular_factor * sum_contrib_V_val\n",
    "                    \n",
    "    return T_tilde_block, V_tilde_block\n",
    "\n",
    "# --- Top-level wrapper for joblib ---\n",
    "def _task_wrapper_for_joblib_top_level(args_tuple_joblib):\n",
    "    (idx1_jl, k1_tuple_jl, idx2_jl, k2_tuple_jl,\n",
    "     data_k1_jl, data_k2_jl,\n",
    "     r_model_jl, rho_model_jl, g_model_jl, kappa_model_jl, mu_model_jl, r_stable_jl,\n",
    "     G_const_jl,\n",
    "     perturbations_direct_coeffs_jl,\n",
    "     s_max_jl,\n",
    "     l1_jl, l2_jl, m_values_l1_jl, m_values_l2_jl, matrix_size_l1m_jl, matrix_size_l2m_jl\n",
    "    ) = args_tuple_joblib\n",
    "\n",
    "    T_block_res, V_block_res = _calculate_k1k2_tilde_block_job_top_level(\n",
    "        k1_tuple_jl, k2_tuple_jl,\n",
    "        data_k1_jl, data_k2_jl,\n",
    "        r_model_jl, rho_model_jl, g_model_jl, kappa_model_jl, mu_model_jl, r_stable_jl,\n",
    "        G_const_jl,\n",
    "        perturbations_direct_coeffs_jl,\n",
    "        s_max_jl,\n",
    "        l1_jl, l2_jl, m_values_l1_jl, m_values_l2_jl, matrix_size_l1m_jl, matrix_size_l2m_jl\n",
    "    )\n",
    "    return idx1_jl, idx2_jl, T_block_res, V_block_res\n",
    "\n",
    "class MoonPerturbationCalculatorGeneralized:\n",
    "    def __init__(self, \n",
    "                 all_spher_nl_tuples, \n",
    "                 all_tor_nl_tuples,   \n",
    "                 full_omega_k2_map, \n",
    "                 model_file,\n",
    "                 eigenfunction_folder_spher, eigenfunction_folder_tor,\n",
    "                 perturbations_input_dictionary, s_max=8):\n",
    "        \n",
    "        self.perturbations_direct_coeffs = perturbations_input_dictionary\n",
    "        self.s_max = s_max\n",
    "        #self.G = Const_G # Store G in self for easy access\n",
    "        self.G = 0\n",
    "\n",
    "        print(f\"\\n--- Initializing Generalized Calculator for ALL specified L values ---\")\n",
    "\n",
    "        print(f\"Loading background model from: {model_file}\")\n",
    "        self._load_background_model(model_file)\n",
    "        self.R_moon = self.r_model[-1]\n",
    "        print(f\"Model loaded: {len(self.r_model)} radial points, R = {self.R_moon / 1e3:.1f} km\")\n",
    "\n",
    "        self.eigen_data = {}\n",
    "        self.k_values_with_data = [] \n",
    "        \n",
    "        potential_k_tuples = []\n",
    "        for n_val, l_val in sorted(list(set(all_spher_nl_tuples))):\n",
    "            potential_k_tuples.append(('S', n_val, l_val))\n",
    "        for n_val, l_val in sorted(list(set(all_tor_nl_tuples))):\n",
    "            if l_val > 0: \n",
    "                potential_k_tuples.append(('T', n_val, l_val))\n",
    "        \n",
    "        print(\"Validating modes (checking for frequency and eigenfunction files)...\\n\")\n",
    "        for k_tuple in potential_k_tuples:\n",
    "            sigma_char, n_val, l_val = k_tuple\n",
    "            if k_tuple not in full_omega_k2_map:\n",
    "                print(f\"  Skipping {k_tuple}: Frequency not found in provided omega_k2_map.\")\n",
    "                continue\n",
    "            if full_omega_k2_map[k_tuple] <= 1e-20:\n",
    "                 print(f\"  Skipping {k_tuple}: Non-positive omega_k^2 ({full_omega_k2_map[k_tuple]:.2e}) found.\")\n",
    "                 continue\n",
    "            if l_val == 0 and sigma_char == 'T':\n",
    "                 print(f\"  Skipping {k_tuple}: Toroidal modes not physical for l=0.\")\n",
    "                 continue\n",
    "            try:\n",
    "                self._check_eigenfunction_file_exists(k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor)\n",
    "                self.k_values_with_data.append(k_tuple)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"  Skipping {k_tuple}: Eigenfunction file not found ({e}).\")\n",
    "        \n",
    "        self.k_values_with_data.sort(key=lambda x: (x[2], x[0] == 'T', x[1])) \n",
    "        \n",
    "        if not self.k_values_with_data:\n",
    "            print(f\"Warning: No valid modes found with both frequency and eigenfunction data. Aborting.\")\n",
    "            self.num_k_modes = 0 \n",
    "            return \n",
    "\n",
    "        self.k_map = {k_tuple: i for i, k_tuple in enumerate(self.k_values_with_data)}\n",
    "        self.num_k_modes = len(self.k_values_with_data)\n",
    "        self.l_values_present = sorted(list(set(k[2] for k in self.k_values_with_data)))\n",
    "        print(f\"\\nFound {self.num_k_modes} valid modes across L values {self.l_values_present} to be processed.\")\n",
    "\n",
    "        self.omega_k2_map_instance = {k: full_omega_k2_map[k] for k in self.k_values_with_data if k in full_omega_k2_map}\n",
    "        self._prepare_all_eigenfunctions(eigenfunction_folder_spher, eigenfunction_folder_tor)\n",
    "\n",
    "        self.results_delta_omega_sq = {} \n",
    "        \n",
    "        self.V_tilde_kk_mm = {} \n",
    "        self.T_tilde_kk_mm = {}\n",
    "        self.V_real_kk_mm = {}\n",
    "        self.T_real_kk_mm = {}\n",
    "\n",
    "    def _get_k_ang(self, l_val):\n",
    "        return np.sqrt(l_val * (l_val + 1)) if l_val > 0 else 1e-9 \n",
    "\n",
    "    def _get_m_values(self, l_val):\n",
    "        return np.arange(-l_val, l_val + 1)\n",
    "\n",
    "    def _get_matrix_size_lm(self, l_val):\n",
    "        return 2 * l_val + 1\n",
    "\n",
    "    def _load_background_model(self, modname):\n",
    "        model = np.loadtxt(modname, skiprows=0)\n",
    "        self.r_model = model[:, 0]\n",
    "        self.rho_model = model[:, 1]\n",
    "        self.vp_model = model[:, 2]\n",
    "        self.vs_model = model[:, 3]\n",
    "        self.mu_model = self.rho_model * self.vs_model**2\n",
    "        self.kappa_model = self.rho_model * (self.vp_model**2 - (4.0/3.0) * self.vs_model**2)\n",
    "        self.kappa_model[self.kappa_model < 0] = 0\n",
    "        self.r_stable = np.maximum(self.r_model, 1e-10) \n",
    "        mass_integrand = self.rho_model * self.r_model**2\n",
    "        mass_r = 4 * np.pi * self._cumulative_integrate(mass_integrand, self.r_model)\n",
    "        self.g_model = np.divide(-self.G * mass_r, self.r_stable**2, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "        if len(self.g_model)>0: self.g_model[0] = 0.0\n",
    "\n",
    "    def _get_eigen_fname_path(self, k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor):\n",
    "        sigma_char, n_val, l_val = k_tuple\n",
    "        n_str_formatted = f\"{n_val:07d}\"\n",
    "        l_str_formatted = f\"{l_val:07d}\" \n",
    "        base_folder = eigenfunction_folder_spher if sigma_char == 'S' else eigenfunction_folder_tor\n",
    "        prefix = \"S.\" if sigma_char == 'S' else \"T.\"\n",
    "        filename_path = os.path.join(base_folder, f\"{prefix}{n_str_formatted}.{l_str_formatted}.ASC\")\n",
    "        if not os.path.exists(filename_path):\n",
    "             raise FileNotFoundError(filename_path)\n",
    "        return filename_path\n",
    "\n",
    "    def _check_eigenfunction_file_exists(self, k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor):\n",
    "        self._get_eigen_fname_path(k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor)\n",
    "\n",
    "    def _load_single_eigenfunction(self, k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor):\n",
    "        sigma_char, n_val, l_val = k_tuple\n",
    "        k_ang_l = self._get_k_ang(l_val)\n",
    "        filename = self._get_eigen_fname_path(k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor)\n",
    "        \n",
    "        df = pd.read_csv(filename, skiprows=1, header=None, delim_whitespace=True)\n",
    "        \n",
    "        if sigma_char == 'S':\n",
    "            U_M_raw = np.array(df[1], dtype=float)[::-1] \n",
    "            V_M_raw = np.array(df[3], dtype=float)[::-1]\n",
    "\n",
    "            if len(U_M_raw) != len(self.r_model):\n",
    "                raise ValueError(f\"Length mismatch for S-mode {k_tuple} U^M. File: {filename}.\")\n",
    "            if len(V_M_raw) != len(self.r_model):\n",
    "                raise ValueError(f\"Length mismatch for S-mode {k_tuple} V^M. File: {filename}.\")\n",
    "\n",
    "            if l_val == 0:\n",
    "                norm_integrand = self.rho_model * (U_M_raw**2) * self.r_model**2\n",
    "                V_M_raw = np.zeros_like(V_M_raw) \n",
    "            else:\n",
    "                norm_integrand = self.rho_model * \\\n",
    "                                 (U_M_raw**2 + k_ang_l**2 * V_M_raw**2) * \\\n",
    "                                 self.r_model**2\n",
    "            \n",
    "            norm_factor_val_sq = self._integrate(norm_integrand, self.r_model)\n",
    "\n",
    "            if norm_factor_val_sq < 1e-20:\n",
    "                print(f\"Warning: S-mode Normalization factor squared for {k_tuple} is very small ({norm_factor_val_sq}). Using 1e10 for sqrt(norm).\")\n",
    "                norm_factor_sqrt = 1e10 \n",
    "            else:\n",
    "                norm_factor_sqrt = np.sqrt(norm_factor_val_sq)\n",
    "            \n",
    "            U_latex = U_M_raw / norm_factor_sqrt\n",
    "            V_latex = (k_ang_l * V_M_raw) / norm_factor_sqrt\n",
    "            if l_val == 0: V_latex = np.zeros_like(V_latex)\n",
    "\n",
    "            return {'U_latex': U_latex, 'V_latex': V_latex}\n",
    "\n",
    "        elif sigma_char == 'T': \n",
    "            W_M_raw = np.array(df[1], dtype=float)[::-1]\n",
    "\n",
    "            if len(W_M_raw) != len(self.r_model):\n",
    "                raise ValueError(f\"Length mismatch for T-mode {k_tuple}. File: {filename}.\")\n",
    "\n",
    "            if l_val == 0: \n",
    "                raise ValueError(f\"Toroidal mode T {k_tuple} requested for l=0, which is not physical.\")\n",
    "            \n",
    "            W_true_unnorm = W_M_raw\n",
    "            norm_integrand = self.rho_model * W_true_unnorm**2 * self.r_model**2\n",
    "            norm_factor_sq = self._integrate(norm_integrand, self.r_model)\n",
    "\n",
    "            if norm_factor_sq < 1e-20:\n",
    "                print(f\"Warning: T-mode Normalization factor squared for {k_tuple} is very small ({norm_factor_sq}). Using 1e10 for sqrt(norm).\")\n",
    "                norm_factor_sqrt = 1e10\n",
    "            else:\n",
    "                norm_factor_sqrt = np.sqrt(norm_factor_sq)\n",
    "            \n",
    "            W_latex = W_true_unnorm / norm_factor_sqrt\n",
    "            return {'W_latex': W_latex}\n",
    "\n",
    "    def _process_single_eigenfunction_job(self, k_tuple_job, eigenfunction_folder_spher_job, eigenfunction_folder_tor_job):\n",
    "        sigma_char, n_val, l_val = k_tuple_job\n",
    "        k_ang_l = self._get_k_ang(l_val)\n",
    "        \n",
    "        raw_efuncs_latex = self._load_single_eigenfunction(k_tuple_job, eigenfunction_folder_spher_job, eigenfunction_folder_tor_job)\n",
    "        data = {'sigma': sigma_char, 'n': n_val, 'l': l_val}\n",
    "\n",
    "        if sigma_char == 'S':\n",
    "            data['u'] = raw_efuncs_latex['U_latex']\n",
    "            data['v_div_k'] = np.divide(raw_efuncs_latex['V_latex'], k_ang_l, \n",
    "                                        out=np.zeros_like(raw_efuncs_latex['V_latex']), where=k_ang_l!=0)\n",
    "            \n",
    "            data['dot_u'] = self._derivative(data['u'], self.r_model)\n",
    "            data['dot_v_div_k'] = self._derivative(data['v_div_k'], self.r_model)\n",
    "            \n",
    "            data['f_val'] = np.divide(2*data['u'] - k_ang_l**2 * data['v_div_k'], self.r_stable, \n",
    "                                      out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            \n",
    "            term_v_div_k_r = np.divide(data['v_div_k'], self.r_stable, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            term_u_r = np.divide(data['u'], self.r_stable, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            data['x_val'] = data['dot_v_div_k'] - term_v_div_k_r + term_u_r\n",
    "            \n",
    "            V_for_P_calc = raw_efuncs_latex['V_latex']\n",
    "            \n",
    "            integrand1_p = self.rho_model * (l_val * data['u'] + V_for_P_calc) * self.r_stable**(l_val + 1) \n",
    "            integrand2_p = self.rho_model * (-(l_val + 1) * data['u'] + V_for_P_calc) * \\\n",
    "                           np.power(self.r_stable, -l_val, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            \n",
    "            int1_p = self._cumulative_integrate(integrand1_p, self.r_model)\n",
    "            int2_total_p = self._integrate(integrand2_p, self.r_model)\n",
    "            int2_cumulative_p = self._cumulative_integrate(integrand2_p, self.r_model)\n",
    "            int2_rev_p = int2_total_p - int2_cumulative_p\n",
    "            \n",
    "            P_term1 = np.divide(int1_p, np.power(self.r_stable, l_val + 1, out=np.ones_like(self.r_model), where=self.r_stable!=0), \n",
    "                                out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            P_term2 = int2_rev_p * np.power(self.r_stable, l_val, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            \n",
    "            data['p_val'] = -4 * np.pi * self.G / (2*l_val + 1) * (P_term1 + P_term2) # Use self.G\n",
    "            if len(data['p_val']) > 0: data['p_val'][0] = 0.0 \n",
    "            data['dot_p'] = self._derivative(data['p_val'], self.r_model)\n",
    "\n",
    "        elif sigma_char == 'T':\n",
    "            data['w_div_k'] = np.divide(raw_efuncs_latex['W_latex'], k_ang_l,\n",
    "                                        out=np.zeros_like(raw_efuncs_latex['W_latex']), where=k_ang_l!=0)\n",
    "            data['dot_w_div_k'] = self._derivative(data['w_div_k'], self.r_model)\n",
    "            term_w_div_k_r = np.divide(data['w_div_k'], self.r_stable, out=np.zeros_like(self.r_model), where=self.r_stable!=0)\n",
    "            data['z_val'] = data['dot_w_div_k'] - term_w_div_k_r\n",
    "        \n",
    "        return k_tuple_job, data\n",
    "\n",
    "    def _prepare_all_eigenfunctions(self, eigenfunction_folder_spher, eigenfunction_folder_tor):\n",
    "        print(\"Preparing all eigenfunction derivatives and related quantities for valid modes (parallelized)...\\n\")\n",
    "        \n",
    "        tasks = [delayed(self._process_single_eigenfunction_job)(k_tuple, eigenfunction_folder_spher, eigenfunction_folder_tor)\n",
    "                 for k_tuple in self.k_values_with_data]\n",
    "        \n",
    "        results = Parallel(n_jobs=-2, backend='loky', verbose=10)(tasks) \n",
    "\n",
    "        for k_tuple_res, data_res in results:\n",
    "            self.eigen_data[k_tuple_res] = data_res\n",
    "        \n",
    "        print(f\"\\nAll {len(self.k_values_with_data)} eigenfunctions processed and collected.\")\n",
    "\n",
    "    def _derivative(self, y, x):\n",
    "        return np.gradient(y, x, edge_order=2)\n",
    "\n",
    "    def _integrate(self, y, x): \n",
    "        return simps(y, x)\n",
    "\n",
    "    def _cumulative_integrate(self, y, x, initial=0): \n",
    "        return cumulative_trapezoid(y, x, initial=initial)\n",
    "\n",
    "    def _calculate_tilde_matrices(self):\n",
    "        if self.num_k_modes == 0: return\n",
    "        print(\"Calculating tilde V and T matrices (parallelized)...\\n\")\n",
    "\n",
    "        job_args = []\n",
    "        for idx1, k1_tuple in enumerate(self.k_values_with_data):\n",
    "            s1_char, n1, l1 = k1_tuple\n",
    "            m_values_l1 = self._get_m_values(l1) \n",
    "            matrix_size_l1m = self._get_matrix_size_lm(l1)\n",
    "\n",
    "            for idx2, k2_tuple in enumerate(self.k_values_with_data):\n",
    "                s2_char, n2, l2 = k2_tuple\n",
    "                m_values_l2 = self._get_m_values(l2)\n",
    "                matrix_size_l2m = self._get_matrix_size_lm(l2)\n",
    "\n",
    "                job_args.append((\n",
    "                    idx1, k1_tuple, idx2, k2_tuple,\n",
    "                    self.eigen_data[k1_tuple], self.eigen_data[k2_tuple],\n",
    "                    self.r_model, self.rho_model, self.g_model, self.kappa_model, self.mu_model, self.r_stable,\n",
    "                    self.G, \n",
    "                    self.perturbations_direct_coeffs,\n",
    "                    self.s_max,\n",
    "                    l1, l2, m_values_l1, m_values_l2, matrix_size_l1m, matrix_size_l2m\n",
    "                ))\n",
    "        \n",
    "        tasks = [delayed(_task_wrapper_for_joblib_top_level)(args) for args in job_args]\n",
    "        results_parallel = Parallel(n_jobs=-2, backend='loky', verbose=10)(tasks)\n",
    "\n",
    "        for idx1_res, idx2_res, T_block_val, V_block_val in results_parallel:\n",
    "            self.T_tilde_kk_mm[(idx1_res, idx2_res)] = T_block_val\n",
    "            self.V_tilde_kk_mm[(idx1_res, idx2_res)] = V_block_val\n",
    "        \n",
    "        print(\"\\nFinished calculating tilde matrices.\")\n",
    "\n",
    "    def _convert_tilde_to_real_matrices(self):\n",
    "        if self.num_k_modes == 0: return\n",
    "        print(\"Converting tilde matrices to real basis...\")\n",
    "\n",
    "        for idx1, k1_tuple in enumerate(self.k_values_with_data):\n",
    "            l1 = k1_tuple[2]\n",
    "            m_values_l1 = self._get_m_values(l1)\n",
    "            matrix_size_l1m = self._get_matrix_size_lm(l1)\n",
    "\n",
    "            for idx2, k2_tuple in enumerate(self.k_values_with_data):\n",
    "                l2 = k2_tuple[2]\n",
    "                m_values_l2 = self._get_m_values(l2)\n",
    "                matrix_size_l2m = self._get_matrix_size_lm(l2)\n",
    "\n",
    "                M_tilde_T_block_curr = self.T_tilde_kk_mm[(idx1, idx2)] \n",
    "                M_tilde_V_block_curr = self.V_tilde_kk_mm[(idx1, idx2)] \n",
    "                \n",
    "                M_real_T_block_curr = np.zeros((matrix_size_l1m, matrix_size_l2m), dtype=complex)\n",
    "                M_real_V_block_curr = np.zeros((matrix_size_l1m, matrix_size_l2m), dtype=complex)\n",
    "\n",
    "                def get_tilde_elem_local(tilde_matrix_local, m_val_for_row, m_val_for_col):\n",
    "                    row_idx = int(m_val_for_row + l1)\n",
    "                    col_idx = int(m_val_for_col + l2)\n",
    "                    return tilde_matrix_local[row_idx, col_idx]\n",
    "\n",
    "                for r_idx_loop, m_row_real_val_orig in enumerate(m_values_l1): \n",
    "                    m_row_real_val = int(m_row_real_val_orig)\n",
    "                    for c_idx_loop, m_col_real_val_orig in enumerate(m_values_l2): \n",
    "                        m_col_real_val = int(m_col_real_val_orig)\n",
    "                        \n",
    "                        val_T_curr, val_V_curr = 0.0j, 0.0j\n",
    "                        \n",
    "                        m_abs_row = abs(m_row_real_val) \n",
    "                        m_abs_col = abs(m_col_real_val) \n",
    "\n",
    "                        if m_row_real_val == 0 and m_col_real_val == 0: \n",
    "                            val_T_curr = get_tilde_elem_local(M_tilde_T_block_curr, 0, 0)\n",
    "                            val_V_curr = get_tilde_elem_local(M_tilde_V_block_curr, 0, 0)\n",
    "                        elif m_row_real_val == 0: \n",
    "                            if m_col_real_val > 0: \n",
    "                                val_T_curr = np.sqrt(2) * np.imag(get_tilde_elem_local(M_tilde_T_block_curr, 0, m_abs_col))\n",
    "                                val_V_curr = np.sqrt(2) * np.imag(get_tilde_elem_local(M_tilde_V_block_curr, 0, m_abs_col))\n",
    "                            else: \n",
    "                                val_T_curr = np.sqrt(2) * np.real(get_tilde_elem_local(M_tilde_T_block_curr, 0, m_abs_col))\n",
    "                                val_V_curr = np.sqrt(2) * np.real(get_tilde_elem_local(M_tilde_V_block_curr, 0, m_abs_col))\n",
    "                        elif m_col_real_val == 0: \n",
    "                            if m_row_real_val > 0: \n",
    "                                val_T_curr = -np.sqrt(2) * np.imag(get_tilde_elem_local(M_tilde_T_block_curr, m_abs_row, 0))\n",
    "                                val_V_curr = -np.sqrt(2) * np.imag(get_tilde_elem_local(M_tilde_V_block_curr, m_abs_row, 0))\n",
    "                            else: \n",
    "                                val_T_curr = np.sqrt(2) * np.real(get_tilde_elem_local(M_tilde_T_block_curr, m_abs_row, 0))\n",
    "                                val_V_curr = np.sqrt(2) * np.real(get_tilde_elem_local(M_tilde_V_block_curr, m_abs_row, 0))\n",
    "                        else: \n",
    "                            term_T_mmprime_tilde = get_tilde_elem_local(M_tilde_T_block_curr, m_abs_row, m_abs_col)\n",
    "                            term_V_mmprime_tilde = get_tilde_elem_local(M_tilde_V_block_curr, m_abs_row, m_abs_col)\n",
    "                            term_T_m_neg_mprime_tilde = get_tilde_elem_local(M_tilde_T_block_curr, m_abs_row, -m_abs_col)\n",
    "                            term_V_m_neg_mprime_tilde = get_tilde_elem_local(M_tilde_V_block_curr, m_abs_row, -m_abs_col)\n",
    "                            \n",
    "                            sign_m_prime_parity = (-1)**m_abs_col \n",
    "\n",
    "                            if m_row_real_val > 0 and m_col_real_val > 0: \n",
    "                                val_T_curr = np.real(term_T_mmprime_tilde - sign_m_prime_parity * term_T_m_neg_mprime_tilde)\n",
    "                                val_V_curr = np.real(term_V_mmprime_tilde - sign_m_prime_parity * term_V_m_neg_mprime_tilde)\n",
    "                            elif m_row_real_val > 0 and m_col_real_val < 0: \n",
    "                                val_T_curr = -np.imag(term_T_mmprime_tilde + sign_m_prime_parity * term_T_m_neg_mprime_tilde)\n",
    "                                val_V_curr = -np.imag(term_V_mmprime_tilde + sign_m_prime_parity * term_V_m_neg_mprime_tilde)\n",
    "                            elif m_row_real_val < 0 and m_col_real_val > 0: \n",
    "                                val_T_curr = np.imag(term_T_mmprime_tilde - sign_m_prime_parity * term_T_m_neg_mprime_tilde) \n",
    "                                val_V_curr = np.imag(term_V_mmprime_tilde - sign_m_prime_parity * term_V_m_neg_mprime_tilde) \n",
    "                            elif m_row_real_val < 0 and m_col_real_val < 0: \n",
    "                                val_T_curr = np.real(term_T_mmprime_tilde + sign_m_prime_parity * term_T_m_neg_mprime_tilde)\n",
    "                                val_V_curr = np.real(term_V_mmprime_tilde + sign_m_prime_parity * term_V_m_neg_mprime_tilde)\n",
    "                        \n",
    "                        M_real_T_block_curr[r_idx_loop, c_idx_loop] = val_T_curr\n",
    "                        M_real_V_block_curr[r_idx_loop, c_idx_loop] = val_V_curr\n",
    "                \n",
    "                self.T_real_kk_mm[(idx1, idx2)] = M_real_T_block_curr.real \n",
    "                self.V_real_kk_mm[(idx1, idx2)] = M_real_V_block_curr.real\n",
    "        \n",
    "        print(\"Finished converting to real basis matrices.\")\n",
    "\n",
    "    def _calculate_delta_omega_sq(self):\n",
    "        if self.num_k_modes == 0: return\n",
    "        print(\"Calculating delta_omega_k_sq...\")\n",
    "        for idx, k_tuple in enumerate(self.k_values_with_data):\n",
    "            l_k = k_tuple[2]\n",
    "            matrix_size_lk_m = self._get_matrix_size_lm(l_k)\n",
    "            nan_array_lm = np.full(matrix_size_lk_m, np.nan + 1j*np.nan)\n",
    "\n",
    "            try: omega_k_sq = self.omega_k2_map_instance[k_tuple]\n",
    "            except KeyError:\n",
    "                print(f\"Error: omega_k^2 not found for k={k_tuple} in instance map. Skipping delta_omega_sq.\")\n",
    "                self.results_delta_omega_sq[idx] = nan_array_lm\n",
    "                continue\n",
    "            \n",
    "            V_kk_block = self.V_real_kk_mm[(idx, idx)]; T_kk_block = self.T_real_kk_mm[(idx, idx)]\n",
    "            W_k_matrix_curr = V_kk_block - omega_k_sq * T_kk_block \n",
    "            \n",
    "            try:\n",
    "                eigvals, _ = np.linalg.eig(W_k_matrix_curr) \n",
    "                sort_indices = np.argsort(np.real(eigvals))\n",
    "                self.results_delta_omega_sq[idx] = eigvals[sort_indices]\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                print(f\"Error diagonalizing W_k for k={k_tuple}: {e}\")\n",
    "                self.results_delta_omega_sq[idx] = nan_array_lm\n",
    "                continue \n",
    "        print(\"Finished delta_omega_k_sq.\")\n",
    "        \n",
    "    def run_calculation(self):\n",
    "        if self.num_k_modes == 0:\n",
    "            print(f\"No valid modes to process. Calculation run aborted.\")\n",
    "            return\n",
    "        self._calculate_tilde_matrices()\n",
    "        self._convert_tilde_to_real_matrices()\n",
    "        self._calculate_delta_omega_sq()\n",
    "        print(f\"All calculations finished for all specified L values.\")\n",
    "\n",
    "    def save_results(self, output_folder_base): \n",
    "        if self.num_k_modes == 0:\n",
    "            print(f\"No results to save as no valid modes were processed.\")\n",
    "            return\n",
    "            \n",
    "        output_folder_unified = Path(output_folder_base)\n",
    "        print(f\"Saving results to unified files in: {output_folder_unified}\")\n",
    "        output_folder_unified.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        d_omega_filename_unified = output_folder_unified / \"ALL_L_delta_omega_km.txt\"\n",
    "        t_real_filename_unified = output_folder_unified / \"ALL_L_T_real_matrix.txt\"\n",
    "        v_real_filename_unified = output_folder_unified / \"ALL_L_V_real_matrix.txt\"\n",
    "\n",
    "        with open(d_omega_filename_unified, 'w') as f_om:\n",
    "            f_om.write(\"# Unified delta_omega_km (frequency shifts) for all processed modes (l,m)\\n\")\n",
    "            f_om.write(\"# delta_omega_km = delta_omega_km_sq / (2 * omega_k_unperturbed)\\n\")\n",
    "            f_om.write(\"# sigma_char,n_val,l_val,m_perturbed_state_idx,Re(delta_omega_km),Im(delta_omega_km)\\n\")\n",
    "            \n",
    "            for k_idx_map_val, k_tuple_val in enumerate(self.k_values_with_data):\n",
    "                sigma_char_val, n_val_val, l_val_k_val = k_tuple_val\n",
    "                \n",
    "                delta_omega_km_sq_values_arr = self.results_delta_omega_sq.get(k_idx_map_val)\n",
    "                if delta_omega_km_sq_values_arr is None: continue\n",
    "\n",
    "                try:\n",
    "                    omega_k_unperturbed_sq_val = self.omega_k2_map_instance[k_tuple_val]\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: Omega_k_sq for {k_tuple_val} not found in instance map during save. Skipping delta_omega for this k.\")\n",
    "                    continue\n",
    "                \n",
    "                nan_array_like = np.full_like(delta_omega_km_sq_values_arr, np.nan + 1j*np.nan, dtype=complex)\n",
    "                if omega_k_unperturbed_sq_val <= 1e-20: \n",
    "                    delta_omega_km_values_arr = nan_array_like\n",
    "                else:\n",
    "                    omega_k_unperturbed_val = np.sqrt(omega_k_unperturbed_sq_val)\n",
    "                    valid_mask = ~np.isnan(delta_omega_km_sq_values_arr) # Should be all valid now\n",
    "                    delta_omega_km_values_arr = nan_array_like.copy() \n",
    "                    delta_omega_km_values_arr[valid_mask] = delta_omega_km_sq_values_arr[valid_mask] / (2 * omega_k_unperturbed_val)\n",
    "\n",
    "                for m_idx_perturbed_state in range(len(delta_omega_km_values_arr)):\n",
    "                    d_om_val_loop = delta_omega_km_values_arr[m_idx_perturbed_state]\n",
    "                    if np.isnan(d_om_val_loop.real) or np.isnan(d_om_val_loop.imag):\n",
    "                        # This might still happen if omega_k_unperturbed_sq_val was too small\n",
    "                        # or if linalg.eig returned NaNs for some reason (though errors are caught)\n",
    "                        f_om.write(f\"{sigma_char_val},{n_val_val},{l_val_k_val},{m_idx_perturbed_state},nan,nan\\n\")\n",
    "                        continue \n",
    "                    f_om.write(f\"{sigma_char_val},{n_val_val},{l_val_k_val},{m_idx_perturbed_state},{d_om_val_loop.real:.8e},{d_om_val_loop.imag:.8e}\\n\")\n",
    "        print(f\"delta_omega_km saved to {d_omega_filename_unified}\")\n",
    "\n",
    "        with open(t_real_filename_unified, 'w') as f_t_real:\n",
    "            f_t_real.write(\"# Unified Real Basis Kinetic Energy Matrix Elements T_k1k2\\n\")\n",
    "            f_t_real.write(\"# T_k1k2 is stored as T_real_kk_mm[(idx1, idx2)]\\n\")\n",
    "            f_t_real.write(\"# sigma1,n1,l1,sigma2,n2,l2,m1_row_idx(for l1),m2_col_idx(for l2),Re(T_val),Im(T_val) (Im(T_val) is 0.0)\\n\")\n",
    "            \n",
    "            for idx1_row_loop, k1_tuple_row_loop in enumerate(self.k_values_with_data):\n",
    "                s1_char_loop, n1_loop, l1_val_loop = k1_tuple_row_loop\n",
    "                matrix_size_l1m = self._get_matrix_size_lm(l1_val_loop)\n",
    "\n",
    "                for idx2_col_loop, k2_tuple_col_loop in enumerate(self.k_values_with_data):\n",
    "                    s2_char_loop, n2_loop, l2_val_loop = k2_tuple_col_loop\n",
    "                    matrix_size_l2m = self._get_matrix_size_lm(l2_val_loop)\n",
    "                    \n",
    "                    T_block_curr = self.T_real_kk_mm.get((idx1_row_loop, idx2_col_loop))\n",
    "                    if T_block_curr is None: continue # Should not happen if calculation ran fully\n",
    "\n",
    "                    for i_row_m1 in range(matrix_size_l1m): \n",
    "                        for j_col_m2 in range(matrix_size_l2m): \n",
    "                            val_to_write = T_block_curr[i_row_m1,j_col_m2] # This is a real float\n",
    "                            if np.isnan(val_to_write): # Check if it's NaN (e.g. if an error occurred upstream)\n",
    "                                f_t_real.write(f\"{s1_char_loop},{n1_loop},{l1_val_loop},{s2_char_loop},{n2_loop},{l2_val_loop},{i_row_m1},{j_col_m2},nan,nan\\n\")\n",
    "                                continue\n",
    "                            f_t_real.write(f\"{s1_char_loop},{n1_loop},{l1_val_loop},{s2_char_loop},{n2_loop},{l2_val_loop},{i_row_m1},{j_col_m2},{val_to_write:.8e},0.0e+00\\n\")\n",
    "        print(f\"T_real_kk_mm saved to {t_real_filename_unified}\")\n",
    "\n",
    "        with open(v_real_filename_unified, 'w') as f_v_real:\n",
    "            f_v_real.write(\"# Unified Real Basis Potential Energy Matrix Elements V_k1k2\\n\")\n",
    "            f_v_real.write(\"# V_k1k2 is stored as V_real_kk_mm[(idx1, idx2)]\\n\")\n",
    "            f_v_real.write(\"# sigma1,n1,l1,sigma2,n2,l2,m1_row_idx(for l1),m2_col_idx(for l2),Re(V_val),Im(V_val) (Im(V_val) is 0.0)\\n\")\n",
    "            \n",
    "            for idx1_row_loop, k1_tuple_row_loop in enumerate(self.k_values_with_data):\n",
    "                s1_char_loop, n1_loop, l1_val_loop = k1_tuple_row_loop\n",
    "                matrix_size_l1m = self._get_matrix_size_lm(l1_val_loop)\n",
    "\n",
    "                for idx2_col_loop, k2_tuple_col_loop in enumerate(self.k_values_with_data):\n",
    "                    s2_char_loop, n2_loop, l2_val_loop = k2_tuple_col_loop\n",
    "                    matrix_size_l2m = self._get_matrix_size_lm(l2_val_loop)\n",
    "                    \n",
    "                    V_block_curr = self.V_real_kk_mm.get((idx1_row_loop, idx2_col_loop))\n",
    "                    if V_block_curr is None: continue\n",
    "\n",
    "                    for i_row_m1 in range(matrix_size_l1m): \n",
    "                        for j_col_m2 in range(matrix_size_l2m): \n",
    "                            val_to_write = V_block_curr[i_row_m1,j_col_m2] # This is a real float\n",
    "                            if np.isnan(val_to_write):\n",
    "                                f_v_real.write(f\"{s1_char_loop},{n1_loop},{l1_val_loop},{s2_char_loop},{n2_loop},{l2_val_loop},{i_row_m1},{j_col_m2},nan,nan\\n\")\n",
    "                                continue\n",
    "                            f_v_real.write(f\"{s1_char_loop},{n1_loop},{l1_val_loop},{s2_char_loop},{n2_loop},{l2_val_loop},{i_row_m1},{j_col_m2},{val_to_write:.8e},0.0e+00\\n\")\n",
    "        print(f\"V_real_kk_mm saved to {v_real_filename_unified}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e9324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Full Generalized Perturbation Calculation Example (Simplified)...\n",
      "Attempting to load S-mode frequencies from: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\\res1.txt\n",
      "  Successfully loaded relevant S-mode frequencies from D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\\res1.txt\n",
      "Attempting to load T-mode frequencies from: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\LunarResponse\\EigenCalculation\\Reference_Model_toroidal\\res1.txt\n",
      "  No T-modes specified for loading frequencies.\n",
      "Total 201 frequency entries compiled for specified (n,l) ranges.\n",
      "Defined example perturbations up to s_max=1\n",
      "\n",
      "--- Initializing Generalized Calculator for ALL specified L values ---\n",
      "Loading background model from: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\MultModel_Results1024\\Reference_Model\\Reference_Model_8000_code.txt\n",
      "Model loaded: 8000 radial points, R = 1737.1 km\n",
      "Validating modes (checking for frequency and eigenfunction files)...\n",
      "\n",
      "\n",
      "Found 201 valid modes across L values [2] to be processed.\n",
      "Preparing all eigenfunction derivatives and related quantities for valid modes (parallelized)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 23 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 out of 201 | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-2)]: Done  15 out of 201 | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-2)]: Done  26 out of 201 | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done  39 out of 201 | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done  52 out of 201 | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-2)]: Done  67 out of 201 | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.19615607042298705s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done  82 out of 201 | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-2)]: Done  99 out of 201 | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-2)]: Done 117 out of 201 | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.18705487251281738s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Done 156 out of 201 | elapsed:    1.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=-2)]: Done 177 out of 201 | elapsed:    2.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done 198 out of 201 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 201 out of 201 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All 201 eigenfunctions processed and collected.\n",
      "Calculating tilde V and T matrices (parallelized)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 23 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.01952981948852539s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-2)]: Done     4 out of 40401 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done    15 out of 40401 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done    26 out of 40401 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done    39 out of 40401 | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.11908531188964844s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-2)]: Done    58 out of 40401 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-2)]: Done    88 out of 40401 | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-2)]: Done   118 out of 40401 | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Batch computation too fast (0.17107892036437988s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-2)]: Done   166 out of 40401 | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-2)]: Done   234 out of 40401 | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-2)]: Done   310 out of 40401 | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-2)]: Done   450 out of 40401 | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-2)]: Done   618 out of 40401 | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-2)]: Done   786 out of 40401 | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-2)]: Done   970 out of 40401 | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done  1154 out of 40401 | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-2)]: Done  1354 out of 40401 | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-2)]: Done  1554 out of 40401 | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-2)]: Done  1770 out of 40401 | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-2)]: Done  1986 out of 40401 | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-2)]: Done  2218 out of 40401 | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-2)]: Done  2450 out of 40401 | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-2)]: Done  2698 out of 40401 | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-2)]: Done  2946 out of 40401 | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-2)]: Done  3210 out of 40401 | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-2)]: Done  3474 out of 40401 | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-2)]: Done  3754 out of 40401 | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-2)]: Done  4034 out of 40401 | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-2)]: Done  4330 out of 40401 | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-2)]: Done  4626 out of 40401 | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-2)]: Done  4938 out of 40401 | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-2)]: Done  5250 out of 40401 | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-2)]: Done  5578 out of 40401 | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-2)]: Done  5906 out of 40401 | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-2)]: Done  6250 out of 40401 | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-2)]: Done  6594 out of 40401 | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-2)]: Done  6954 out of 40401 | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-2)]: Done  7314 out of 40401 | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-2)]: Done  7690 out of 40401 | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-2)]: Done  8066 out of 40401 | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-2)]: Done  8458 out of 40401 | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-2)]: Done  8850 out of 40401 | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-2)]: Done  9258 out of 40401 | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-2)]: Done  9666 out of 40401 | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-2)]: Done 10090 out of 40401 | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-2)]: Done 10514 out of 40401 | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-2)]: Done 10954 out of 40401 | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-2)]: Done 11394 out of 40401 | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-2)]: Done 11850 out of 40401 | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-2)]: Done 12306 out of 40401 | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-2)]: Done 12778 out of 40401 | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-2)]: Done 13250 out of 40401 | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-2)]: Done 13738 out of 40401 | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-2)]: Done 14226 out of 40401 | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-2)]: Done 14730 out of 40401 | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-2)]: Done 15234 out of 40401 | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-2)]: Done 15754 out of 40401 | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-2)]: Done 16274 out of 40401 | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-2)]: Done 16810 out of 40401 | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-2)]: Done 17346 out of 40401 | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-2)]: Done 17898 out of 40401 | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-2)]: Done 18450 out of 40401 | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-2)]: Done 19018 out of 40401 | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-2)]: Done 19586 out of 40401 | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-2)]: Done 20170 out of 40401 | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-2)]: Done 20754 out of 40401 | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-2)]: Done 21354 out of 40401 | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-2)]: Done 21954 out of 40401 | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-2)]: Done 22570 out of 40401 | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-2)]: Done 23186 out of 40401 | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-2)]: Done 23818 out of 40401 | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-2)]: Done 24450 out of 40401 | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-2)]: Done 25098 out of 40401 | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-2)]: Done 25746 out of 40401 | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-2)]: Done 26410 out of 40401 | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-2)]: Done 27074 out of 40401 | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-2)]: Done 27754 out of 40401 | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-2)]: Done 28434 out of 40401 | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-2)]: Done 29130 out of 40401 | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-2)]: Done 29826 out of 40401 | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-2)]: Done 30538 out of 40401 | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-2)]: Done 31250 out of 40401 | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-2)]: Done 31978 out of 40401 | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-2)]: Done 32706 out of 40401 | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-2)]: Done 33450 out of 40401 | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-2)]: Done 34194 out of 40401 | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-2)]: Done 34954 out of 40401 | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-2)]: Done 35714 out of 40401 | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-2)]: Done 36490 out of 40401 | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-2)]: Done 37266 out of 40401 | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-2)]: Done 38058 out of 40401 | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-2)]: Done 38850 out of 40401 | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-2)]: Done 39658 out of 40401 | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-2)]: Done 40277 out of 40401 | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done 40401 out of 40401 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished calculating tilde matrices.\n",
      "Converting tilde matrices to real basis...\n",
      "Finished converting to real basis matrices.\n",
      "Calculating delta_omega_k_sq...\n",
      "Finished delta_omega_k_sq.\n",
      "All calculations finished for all specified L values.\n",
      "Saving results to unified files in: TV_0S2-200S2_NoTor_matrix\n",
      "delta_omega_km saved to TV_0S2-200S2_NoTor_matrix\\ALL_L_delta_omega_km.txt\n",
      "T_real_kk_mm saved to TV_0S2-200S2_NoTor_matrix\\ALL_L_T_real_matrix.txt\n",
      "V_real_kk_mm saved to TV_0S2-200S2_NoTor_matrix\\ALL_L_V_real_matrix.txt\n",
      "\n",
      "--- Performing independent frequency listing and ratio calculation ---\n",
      "Sorted frequencies with ratios saved to: TV_0S2-200S2_NoTor_matrix\\ALL_L_sorted_frequencies_with_ratios.txt\n",
      "\n",
      "\n",
      "Full Generalized Perturbation Calculation Example (Simplified) Finished.\n",
      "Results, if any, saved in subfolder: D:\\Study\\Research & Survey\\Seismic GW detector\\MyWork\\Inverse-1D-pert\\TV_0S2-200S2_NoTor_matrix\n",
      "********************************************************************************\n",
      "*** This was an illustrative example run. Ensure paths and data are correct. ***\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Main Script Example (Adapted for Global Calculator)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setting up Full Generalized Perturbation Calculation Example (Simplified)...\")\n",
    "\n",
    "    # --- RANGES (USER: Adapt these) ---\n",
    "    L_MIN_SPHER_GLOBAL = 2\n",
    "    L_MAX_SPHER_GLOBAL = 2 \n",
    "    N_MIN_SPHER_GLOBAL = 0\n",
    "    N_MAX_SPHER_GLOBAL = 200\n",
    "\n",
    "    L_MIN_TOR_GLOBAL = 0 \n",
    "    L_MAX_TOR_GLOBAL = 0 # Set to 0 if no toroidal, or e.g. 2 if L=2 toroidal needed\n",
    "    N_MIN_TOR_GLOBAL = 0\n",
    "    N_MAX_TOR_GLOBAL = 0 # Set to 0 if no toroidal\n",
    "\n",
    "    # --- Prepare lists of (n,l) tuples for the calculator ---\n",
    "    all_spher_nl_tuples_main = []\n",
    "    if L_MAX_SPHER_GLOBAL >= L_MIN_SPHER_GLOBAL and N_MAX_SPHER_GLOBAL >= N_MIN_SPHER_GLOBAL :\n",
    "        for l_spher in range(L_MIN_SPHER_GLOBAL, L_MAX_SPHER_GLOBAL + 1):\n",
    "            for n_spher in range(N_MIN_SPHER_GLOBAL, N_MAX_SPHER_GLOBAL + 1):\n",
    "                all_spher_nl_tuples_main.append((n_spher, l_spher))\n",
    "    \n",
    "    all_tor_nl_tuples_main = []\n",
    "    if L_MAX_TOR_GLOBAL >= L_MIN_TOR_GLOBAL and N_MAX_TOR_GLOBAL >= N_MIN_TOR_GLOBAL:\n",
    "        for l_tor in range(L_MIN_TOR_GLOBAL, L_MAX_TOR_GLOBAL + 1):\n",
    "            if l_tor == 0: continue # Toroidal not for l=0\n",
    "            for n_tor in range(N_MIN_TOR_GLOBAL, N_MAX_TOR_GLOBAL + 1):\n",
    "                all_tor_nl_tuples_main.append((n_tor, l_tor))\n",
    "    \n",
    "    if not all_spher_nl_tuples_main and not all_tor_nl_tuples_main:\n",
    "        print(\"Warning: No (n,l) mode combinations specified for processing. Exiting.\")\n",
    "        # sys.exit() # Or handle as appropriate\n",
    "\n",
    "    # --- PATHS (USER: Adapt these to your file structure) ---\\n\",\n",
    "    modename = \"Reference_Model\" # Example mode name, can be used in paths\n",
    "\n",
    "    spheroidal_data_base_dir_main = Path(\"D:\\\\Study\\\\Research & Survey\\\\Seismic GW detector\\\\MyWork\\\\Inverse-1D-pert\\\\MultModel_Results1024\\\\\"+modename) \n",
    "    eigen_freq_file_s_main = spheroidal_data_base_dir_main / \"res1.txt\"\n",
    "    eigen_func_folder_s_main = spheroidal_data_base_dir_main / \"db25new\" \n",
    "    \n",
    "    toroidal_data_base_dir_main = Path(\"D:\\\\Study\\\\Research & Survey\\\\Seismic GW detector\\\\MyWork\\\\LunarResponse\\\\EigenCalculation\\\\\"+modename+\"_toroidal\")\n",
    "    eigen_freq_file_t_main = toroidal_data_base_dir_main / \"res1.txt\"\n",
    "    eigen_func_folder_t_main = toroidal_data_base_dir_main / \"db25new\" \n",
    "    \n",
    "    model_file_path_main = Path(\"D:\\\\Study\\\\Research & Survey\\\\Seismic GW detector\\\\MyWork\\\\Inverse-1D-pert\\\\MultModel_Results1024\\\\\"+modename+\"\\\\\"+modename+\"_8000_code.txt\")\n",
    "    \n",
    "    # Output folder name can still reflect the overall ranges\n",
    "    s_l_range_str = f\"{N_MIN_SPHER_GLOBAL}S{L_MIN_SPHER_GLOBAL}-{N_MAX_SPHER_GLOBAL}S{L_MAX_SPHER_GLOBAL}\" if all_spher_nl_tuples_main else \"NoSpher\"\n",
    "    t_l_range_str = f\"{N_MIN_TOR_GLOBAL}T{L_MIN_TOR_GLOBAL}-{N_MAX_TOR_GLOBAL}T{L_MAX_TOR_GLOBAL}\" if all_tor_nl_tuples_main else \"NoTor\"\n",
    "    # Changed output folder name slightly to indicate simplified results\n",
    "    output_folder_base_main = Path(f\"TV_{s_l_range_str}_{t_l_range_str}_matrix\")\n",
    "    # --- END PATHS ---\n",
    "\n",
    "    # --- Load Frequencies ---\n",
    "    full_omega_k2_map_from_file = {}\n",
    "    def _load_frequencies_from_res1_helper(res1_path, sigma_char, target_map, \n",
    "                                           nl_tuples_to_consider): # nl_tuples_to_consider is list of (n,l)\n",
    "        print(f\"Attempting to load {sigma_char}-mode frequencies from: {res1_path}\")\n",
    "        # Create a set of (n,l) for faster lookup if nl_tuples_to_consider is large\n",
    "        nl_set_to_consider = set(nl_tuples_to_consider)\n",
    "        if not nl_set_to_consider:\n",
    "            print(f\"  No {sigma_char}-modes specified for loading frequencies.\")\n",
    "            return\n",
    "\n",
    "        if res1_path.exists():\n",
    "            try:\n",
    "                # Original code used np.loadtxt(res1_path) which implies space/tab delimited\n",
    "                # and assumes header might be handled by skiprows or comments\n",
    "                # For standard res1.txt, often first line is header\n",
    "                data_freq = np.loadtxt(res1_path, comments='#') # Use comments='#' or skiprows=1\n",
    "                if data_freq.ndim == 1: data_freq = data_freq.reshape(1, -1) \n",
    "                for row in data_freq:\n",
    "                    # Original code used row[0], row[1], row[3]\n",
    "                    # n l T Q f\n",
    "                    # 0 1 2 3 4  <- indices\n",
    "                    # Assuming freq_mhz = row[4] if 5 columns, or row[3] if 4 columns (like in original)\n",
    "                    # Let's stick to the original interpretation: n, l, (some T/Q), f\n",
    "                    n_file, l_file = int(row[0]), int(row[1])\n",
    "                    if (n_file, l_file) not in nl_set_to_consider: continue \n",
    "                    \n",
    "                    freq_mhz = float(row[3]) # As per original example's interpretation of res1.txt\n",
    "                    omega_sq_val = (freq_mhz * 1e-3 * 2 * np.pi)**2\n",
    "                    if omega_sq_val > 1e-20: \n",
    "                        target_map[(sigma_char, n_file, l_file)] = omega_sq_val\n",
    "                    else:\n",
    "                        print(f\"  Warning: Skipping zero/negative omega_sq ({omega_sq_val:.2e}) for ({sigma_char},{n_file},{l_file}) from file {res1_path}\")\n",
    "                print(f\"  Successfully loaded relevant {sigma_char}-mode frequencies from {res1_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error parsing {res1_path}: {e}. Frequencies for {sigma_char}-modes might be missing or incomplete.\")\n",
    "        else:\n",
    "            print(f\"  Warning: Eigenfrequency file '{res1_path}' for {sigma_char}-modes not found.\")\n",
    "        \n",
    "    _load_frequencies_from_res1_helper(eigen_freq_file_s_main, 'S', full_omega_k2_map_from_file, all_spher_nl_tuples_main)\n",
    "    _load_frequencies_from_res1_helper(eigen_freq_file_t_main, 'T', full_omega_k2_map_from_file, all_tor_nl_tuples_main)\n",
    "    print(f\"Total {len(full_omega_k2_map_from_file)} frequency entries compiled for specified (n,l) ranges.\")\n",
    "\n",
    "    # --- Dummy Model File (if needed, using original logic for checking existence) ---\\n\",\n",
    "    r_surface_moon_dummy = 1737.1e3 # Used if creating dummy\n",
    "    ''' # This block is from the original, kept for structural similarity, but usually real file is expected\n",
    "    if not model_file_path_main.exists():\n",
    "        print(f\"Creating dummy model file: {model_file_path_main}\")\n",
    "        dummy_r_pts = np.linspace(0,r_surface_moon_dummy,200); dummy_rho_pts = np.full_like(dummy_r_pts,3340.0)\n",
    "        dummy_vp_pts = np.full_like(dummy_r_pts,5000.0); dummy_vs_pts = np.full_like(dummy_r_pts,3000.0)\n",
    "        dummy_vs_pts[dummy_r_pts < 0.3*r_surface_moon_dummy]=0 # Simple core with Vs=0\n",
    "        np.savetxt(model_file_path_main,np.array([dummy_r_pts,dummy_rho_pts,dummy_vp_pts,dummy_vs_pts]).T,fmt=\"%.6e\",header=\"r rho vp vs\")\n",
    "    '''\n",
    "    # --- Perturbations (EXACTLY AS IN ORIGINAL) ---\n",
    "    s_perturbation_degree_main = 1 \n",
    "    delta_d_perturbations_main = {\n",
    "(352500, 0, 0): 352500*0.002,\n",
    "                                  }\n",
    "    delta_rho_perturbations_main = {\n",
    "\n",
    "                                    }\n",
    "    \n",
    "    \n",
    "    delta_kappa_perturbations_main = {\n",
    "\n",
    "\n",
    "                                    }\n",
    "    \n",
    "    delta_mu_perturbations_main = {\n",
    "\n",
    "                                    }\n",
    "    \n",
    "    PERTURBATION_SCALE = 1  # 例如放大2倍，缩小为0.5倍，按需设置\n",
    "\n",
    "    # 缩放 delta_d_perturbations_main\n",
    "    for k in delta_d_perturbations_main:\n",
    "        delta_d_perturbations_main[k] *= PERTURBATION_SCALE\n",
    "\n",
    "    # 缩放 delta_rho_perturbations_main\n",
    "    for k in delta_rho_perturbations_main:\n",
    "        v = delta_rho_perturbations_main[k]\n",
    "        if isinstance(v, dict) and 'value' in v:\n",
    "            v['value'] *= PERTURBATION_SCALE\n",
    "        elif isinstance(v, (int, float)):\n",
    "            delta_rho_perturbations_main[k] *= PERTURBATION_SCALE\n",
    "\n",
    "    all_perturbations_main = {'delta_rho':delta_rho_perturbations_main,'delta_mu':delta_mu_perturbations_main,'delta_kappa':delta_kappa_perturbations_main, 'delta_d':delta_d_perturbations_main}\n",
    "    print(f\"Defined example perturbations up to s_max={s_perturbation_degree_main}\")\n",
    "    \n",
    "    output_folder_base_main.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- Instantiate and Run Calculator (once for all modes) ---\n",
    "    # Threshold parameters removed from instantiation\n",
    "    if not all_spher_nl_tuples_main and not all_tor_nl_tuples_main:\n",
    "        print(\"\\nNo modes specified. Skipping calculation.\")\n",
    "    elif not model_file_path_main.exists(): # Check if model file exists before proceeding\n",
    "        print(f\"\\nModel file {model_file_path_main} not found. Skipping calculation.\")\n",
    "    elif not full_omega_k2_map_from_file and (all_spher_nl_tuples_main or all_tor_nl_tuples_main) : # Check if freqs are loaded if modes are specified\n",
    "        print(f\"\\nNo frequencies loaded from {eigen_freq_file_s_main} or {eigen_freq_file_t_main} for the specified modes. Skipping calculation.\")\n",
    "    else:\n",
    "        calculator_global = MoonPerturbationCalculatorGeneralized(\n",
    "            all_spher_nl_tuples=all_spher_nl_tuples_main,\n",
    "            all_tor_nl_tuples=all_tor_nl_tuples_main,\n",
    "            full_omega_k2_map=full_omega_k2_map_from_file,\n",
    "            model_file=model_file_path_main,\n",
    "            eigenfunction_folder_spher=eigen_func_folder_s_main, \n",
    "            eigenfunction_folder_tor=eigen_func_folder_t_main,\n",
    "            perturbations_input_dictionary=all_perturbations_main, \n",
    "            s_max=s_perturbation_degree_main\n",
    "            # transform_matrix_threshold and delta_omega_ratio_threshold are removed\n",
    "        )\n",
    "\n",
    "        if calculator_global.num_k_modes > 0: \n",
    "            calculator_global.run_calculation()\n",
    "            calculator_global.save_results(output_folder_base_main)\n",
    "        else: \n",
    "            print(f\"Skipping calculations and saving as no valid modes were found/processed for the specified N, L ranges globally.\")\n",
    "\n",
    "\n",
    "     # --- Independent Frequency Listing and Ratio Calculation ---\n",
    "    print(\"\\n--- Performing independent frequency listing and ratio calculation ---\")\n",
    "    if not full_omega_k2_map_from_file:\n",
    "        print(\"No frequencies loaded (full_omega_k2_map_from_file is empty). Cannot list frequencies.\")\n",
    "    else:\n",
    "        # Ensure output directory exists for this new file as well\n",
    "        output_folder_base_main.mkdir(parents=True, exist_ok=True)\n",
    "        sorted_freq_list_file = output_folder_base_main / \"ALL_L_sorted_frequencies_with_ratios.txt\"\n",
    "\n",
    "        # Convert omega_k^2 to frequency in mHz and store with quantum numbers\n",
    "        # k_tuple is (sigma_char, n, l)\n",
    "        # omega_k2_map_from_file value is omega_k^2\n",
    "        freq_data_list = []\n",
    "        for k_tuple, omega_k2_val in full_omega_k2_map_from_file.items():\n",
    "            sigma_char, n_val, l_val = k_tuple\n",
    "            freq_hz = np.sqrt(omega_k2_val) / (2 * np.pi)\n",
    "            freq_mhz = freq_hz * 1000.0\n",
    "            freq_data_list.append({'sigma': sigma_char, 'n': n_val, 'l': l_val, 'freq_mhz': freq_mhz})\n",
    "\n",
    "        # Sort by frequency\n",
    "        sorted_freq_data = sorted(freq_data_list, key=lambda x: x['freq_mhz'])\n",
    "\n",
    "        with open(sorted_freq_list_file, 'w') as f_sfl:\n",
    "            f_sfl.write(\"# Sorted list of unperturbed frequencies for all S and T modes considered.\\n\")\n",
    "            f_sfl.write(\"# Format: sigma_char, n_val, l_val, Freq(mHz), Ratio_Lower, Ratio_Upper\\n\")\n",
    "            f_sfl.write(\"# Ratio_Lower = (Freq_current - Freq_previous) / Freq_current\\n\")\n",
    "            f_sfl.write(\"# Ratio_Upper = (Freq_next - Freq_current) / Freq_current\\n\")\n",
    "            f_sfl.write(\"# Ratios are 'nan' for the first and last frequency in the list.\\n\")\n",
    "\n",
    "            num_freqs = len(sorted_freq_data)\n",
    "            for i, data_item in enumerate(sorted_freq_data):\n",
    "                s, n, l, f_mhz = data_item['sigma'], data_item['n'], data_item['l'], data_item['freq_mhz']\n",
    "                \n",
    "                ratio_lower_str = \"nan\"\n",
    "                ratio_upper_str = \"nan\"\n",
    "\n",
    "                if 0 < i < num_freqs -1 : # Only for items not at the ends\n",
    "                    f_prev = sorted_freq_data[i-1]['freq_mhz']\n",
    "                    f_next = sorted_freq_data[i+1]['freq_mhz']\n",
    "                    \n",
    "                    if abs(f_mhz) > 1e-9: # Avoid division by zero if frequency is tiny\n",
    "                        ratio_lower = (f_mhz - f_prev) / f_mhz\n",
    "                        ratio_upper = (f_next - f_mhz) / f_mhz\n",
    "                        ratio_lower_str = f\"{ratio_lower:.4f}\" # 4 decimal places for ratio\n",
    "                        ratio_upper_str = f\"{ratio_upper:.4f}\"\n",
    "                    else:\n",
    "                        ratio_lower_str = \"div_zero\"\n",
    "                        ratio_upper_str = \"div_zero\"\n",
    "                elif i == 0 and num_freqs > 1: # First item, if there's a next\n",
    "                    f_next = sorted_freq_data[i+1]['freq_mhz']\n",
    "                    if abs(f_mhz) > 1e-9:\n",
    "                        ratio_upper = (f_next - f_mhz) / f_mhz\n",
    "                        ratio_upper_str = f\"{ratio_upper:.4f}\"\n",
    "                    else:\n",
    "                        ratio_upper_str = \"div_zero\"\n",
    "                elif i == num_freqs - 1 and num_freqs > 1: # Last item, if there's a previous\n",
    "                    f_prev = sorted_freq_data[i-1]['freq_mhz']\n",
    "                    if abs(f_mhz) > 1e-9:\n",
    "                        ratio_lower = (f_mhz - f_prev) / f_mhz\n",
    "                        ratio_lower_str = f\"{ratio_lower:.4f}\"\n",
    "                    else:\n",
    "                        ratio_lower_str = \"div_zero\"\n",
    "                \n",
    "                # If only one frequency, both ratios remain \"nan\"\n",
    "                \n",
    "                f_sfl.write(f\"{s},{n},{l},{f_mhz:.6e},{ratio_lower_str},{ratio_upper_str}\\n\")\n",
    "        print(f\"Sorted frequencies with ratios saved to: {sorted_freq_list_file}\")\n",
    "    # --- End of Independent Frequency Listing ---\n",
    "\n",
    "    print(\"\\n\\nFull Generalized Perturbation Calculation Example (Simplified) Finished.\")\n",
    "    print(f\"Results, if any, saved in subfolder: {output_folder_base_main.resolve()}\")\n",
    "    print(\"********************************************************************************\")\n",
    "    print(\"*** This was an illustrative example run. Ensure paths and data are correct. ***\")\n",
    "    print(\"********************************************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
